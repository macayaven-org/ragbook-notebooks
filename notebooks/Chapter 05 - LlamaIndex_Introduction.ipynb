{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2005%20-%20LlamaIndex_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9gRt2BXzwASv"
   },
   "outputs": [],
   "source": [
    "!pip install -q llama-index.post3 deeplake openai cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Using cached llama_index-0.10.59-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting deeplake\n",
      "  Using cached deeplake-3.9.16-py3-none-any.whl\n",
      "Collecting openai\n",
      "  Using cached openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting cohere\n",
      "  Using cached cohere-5.6.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.10.59 (from llama-index)\n",
      "  Using cached llama_index_core-0.10.59-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.1.32-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached aiohttp-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy<2.0.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting boto3 (from deeplake)\n",
      "  Using cached boto3-1.34.153-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting click (from deeplake)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pathos (from deeplake)\n",
      "  Using cached pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting humbug>=0.3.1 (from deeplake)\n",
      "  Using cached humbug-0.3.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting lz4 (from deeplake)\n",
      "  Using cached lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting pyjwt (from deeplake)\n",
      "  Using cached PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pydantic (from deeplake)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting libdeeplake==0.0.138 (from deeplake)\n",
      "  Using cached libdeeplake-0.0.138-cp310-cp310-manylinux2014_x86_64.whl.metadata (352 bytes)\n",
      "Collecting aioboto3>=10.4.0 (from deeplake)\n",
      "  Using cached aioboto3-13.1.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting dill (from libdeeplake==0.0.138->deeplake)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Using cached fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
      "  Using cached parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tokenizers<1,>=0.15 (from cohere)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
      "  Using cached types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
      "  Downloading langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiobotocore==2.13.1 (from aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake)\n",
      "  Using cached aiobotocore-2.13.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting aiofiles>=23.2.1 (from aioboto3>=10.4.0->deeplake)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting botocore<1.34.132,>=1.34.70 (from aiobotocore==2.13.1->aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake)\n",
      "  Using cached botocore-1.34.131-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.13.1->aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake)\n",
      "  Using cached aioitertools-0.11.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting boto3 (from deeplake)\n",
      "  Using cached boto3-1.34.131-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached aiohappyeyeballs-2.3.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->deeplake)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->deeplake)\n",
      "  Using cached s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting certifi (from httpx->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
      "  Using cached llama_cloud-0.0.11-py3-none-any.whl.metadata (751 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
      "  Using cached llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->deeplake)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic->deeplake)\n",
      "  Using cached pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<1,>=0.15->cohere)\n",
      "  Using cached huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->deeplake)\n",
      "  Using cached ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->deeplake)\n",
      "  Using cached pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->deeplake)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.34.132,>=1.34.70->aiobotocore==2.13.1->aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore<1.34.132,>=1.34.70->aiobotocore==2.13.1->aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached llama_index-0.10.59-py3-none-any.whl (6.8 kB)\n",
      "Using cached llama_index_core-0.10.59-py3-none-any.whl (15.5 MB)\n",
      "Using cached libdeeplake-0.0.138-cp310-cp310-manylinux2014_x86_64.whl (16.8 MB)\n",
      "Using cached openai-1.38.0-py3-none-any.whl (335 kB)\n",
      "Using cached cohere-5.6.2-py3-none-any.whl (177 kB)\n",
      "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aioboto3-13.1.1-py3-none-any.whl (34 kB)\n",
      "Using cached aiobotocore-2.13.1-py3-none-any.whl (76 kB)\n",
      "Using cached aiohttp-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached boto3-1.34.131-py3-none-any.whl (139 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached humbug-0.3.2-py3-none-any.whl (15 kB)\n",
      "Downloading langchain_core-0.2.28-py3-none-any.whl (379 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
      "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Using cached llama_index_llms_openai-0.1.27-py3-none-any.whl (11 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.1.32-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "Using cached PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiohappyeyeballs-2.3.4-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached botocore-1.34.131-py3-none-any.whl (12.3 MB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "Using cached huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
      "Using cached llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Using cached ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Using cached s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, regex, PyYAML, pyjwt, ppft, pox, pillow, parameterized, packaging, orjson, numpy, networkx, nest-asyncio, mypy-extensions, multidict, lz4, jsonpointer, joblib, jmespath, idna, httpx-sse, h11, greenlet, fsspec, frozenlist, filelock, fastavro, exceptiongroup, distro, dill, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aioitertools, aiohappyeyeballs, aiofiles, yarl, typing-inspect, types-requests, SQLAlchemy, requests, python-dateutil, pypdf, pydantic-core, nltk, multiprocess, marshmallow, libdeeplake, jsonpatch, httpcore, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, pydantic, pathos, pandas, humbug, huggingface-hub, httpx, dataclasses-json, botocore, aiohttp, tokenizers, s3transfer, openai, llama-cloud, langsmith, aiobotocore, llama-index-legacy, llama-index-core, langchain-core, boto3, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, cohere, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, aioboto3, llama-index-program-openai, deeplake, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: striprtf\n",
      "    Found existing installation: striprtf 0.0.26\n",
      "    Uninstalling striprtf-0.0.26:\n",
      "      Successfully uninstalled striprtf-0.0.26\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: dirtyjson\n",
      "    Found existing installation: dirtyjson 1.0.8\n",
      "    Uninstalling dirtyjson-1.0.8:\n",
      "      Successfully uninstalled dirtyjson-1.0.8\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.1\n",
      "    Uninstalling tzdata-2024.1:\n",
      "      Successfully uninstalled tzdata-2024.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.5.0\n",
      "    Uninstalling tenacity-8.5.0:\n",
      "      Successfully uninstalled tenacity-8.5.0\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.5\n",
      "    Uninstalling soupsieve-2.5:\n",
      "      Successfully uninstalled soupsieve-2.5\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.1\n",
      "    Uninstalling sniffio-1.3.1:\n",
      "      Successfully uninstalled sniffio-1.3.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.7.24\n",
      "    Uninstalling regex-2024.7.24:\n",
      "      Successfully uninstalled regex-2024.7.24\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: pyjwt\n",
      "    Found existing installation: PyJWT 2.9.0\n",
      "    Uninstalling PyJWT-2.9.0:\n",
      "      Successfully uninstalled PyJWT-2.9.0\n",
      "  Attempting uninstall: ppft\n",
      "    Found existing installation: ppft 1.7.6.8\n",
      "    Uninstalling ppft-1.7.6.8:\n",
      "      Successfully uninstalled ppft-1.7.6.8\n",
      "  Attempting uninstall: pox\n",
      "    Found existing installation: pox 0.3.4\n",
      "    Uninstalling pox-0.3.4:\n",
      "      Successfully uninstalled pox-0.3.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "  Attempting uninstall: parameterized\n",
      "    Found existing installation: parameterized 0.9.0\n",
      "    Uninstalling parameterized-0.9.0:\n",
      "      Successfully uninstalled parameterized-0.9.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.3\n",
      "    Uninstalling networkx-3.3:\n",
      "      Successfully uninstalled networkx-3.3\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 1.0.0\n",
      "    Uninstalling mypy-extensions-1.0.0:\n",
      "      Successfully uninstalled mypy-extensions-1.0.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.5\n",
      "    Uninstalling multidict-6.0.5:\n",
      "      Successfully uninstalled multidict-6.0.5\n",
      "  Attempting uninstall: lz4\n",
      "    Found existing installation: lz4 4.3.3\n",
      "    Uninstalling lz4-4.3.3:\n",
      "      Successfully uninstalled lz4-4.3.3\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: httpx-sse\n",
      "    Found existing installation: httpx-sse 0.4.0\n",
      "    Uninstalling httpx-sse-0.4.0:\n",
      "      Successfully uninstalled httpx-sse-0.4.0\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.0.3\n",
      "    Uninstalling greenlet-3.0.3:\n",
      "      Successfully uninstalled greenlet-3.0.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.1\n",
      "    Uninstalling frozenlist-1.4.1:\n",
      "      Successfully uninstalled frozenlist-1.4.1\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.15.4\n",
      "    Uninstalling filelock-3.15.4:\n",
      "      Successfully uninstalled filelock-3.15.4\n",
      "  Attempting uninstall: fastavro\n",
      "    Found existing installation: fastavro 1.9.5\n",
      "    Uninstalling fastavro-1.9.5:\n",
      "      Successfully uninstalled fastavro-1.9.5\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.2.2\n",
      "    Uninstalling exceptiongroup-1.2.2:\n",
      "      Successfully uninstalled exceptiongroup-1.2.2\n",
      "  Attempting uninstall: distro\n",
      "    Found existing installation: distro 1.9.0\n",
      "    Uninstalling distro-1.9.0:\n",
      "      Successfully uninstalled distro-1.9.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.7.4\n",
      "    Uninstalling certifi-2024.7.4:\n",
      "      Successfully uninstalled certifi-2024.7.4\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.2.0\n",
      "    Uninstalling attrs-23.2.0:\n",
      "      Successfully uninstalled attrs-23.2.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 4.0.3\n",
      "    Uninstalling async-timeout-4.0.3:\n",
      "      Successfully uninstalled async-timeout-4.0.3\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "  Attempting uninstall: aioitertools\n",
      "    Found existing installation: aioitertools 0.11.0\n",
      "    Uninstalling aioitertools-0.11.0:\n",
      "      Successfully uninstalled aioitertools-0.11.0\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.3.4\n",
      "    Uninstalling aiohappyeyeballs-2.3.4:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.3.4\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 24.1.0\n",
      "    Uninstalling aiofiles-24.1.0:\n",
      "      Successfully uninstalled aiofiles-24.1.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.4\n",
      "    Uninstalling yarl-1.9.4:\n",
      "      Successfully uninstalled yarl-1.9.4\n",
      "  Attempting uninstall: typing-inspect\n",
      "    Found existing installation: typing-inspect 0.9.0\n",
      "    Uninstalling typing-inspect-0.9.0:\n",
      "      Successfully uninstalled typing-inspect-0.9.0\n",
      "  Attempting uninstall: types-requests\n",
      "    Found existing installation: types-requests 2.32.0.20240712\n",
      "    Uninstalling types-requests-2.32.0.20240712:\n",
      "      Successfully uninstalled types-requests-2.32.0.20240712\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.31\n",
      "    Uninstalling SQLAlchemy-2.0.31:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.31\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.3.1\n",
      "    Uninstalling pypdf-4.3.1:\n",
      "      Successfully uninstalled pypdf-4.3.1\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.21.3\n",
      "    Uninstalling marshmallow-3.21.3:\n",
      "      Successfully uninstalled marshmallow-3.21.3\n",
      "  Attempting uninstall: libdeeplake\n",
      "    Found existing installation: libdeeplake 0.0.138\n",
      "    Uninstalling libdeeplake-0.0.138:\n",
      "      Successfully uninstalled libdeeplake-0.0.138\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: deprecated\n",
      "    Found existing installation: Deprecated 1.2.14\n",
      "    Uninstalling Deprecated-1.2.14:\n",
      "      Successfully uninstalled Deprecated-1.2.14\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.3\n",
      "    Uninstalling beautifulsoup4-4.12.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.4.0\n",
      "    Uninstalling anyio-4.4.0:\n",
      "      Successfully uninstalled anyio-4.4.0\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "  Attempting uninstall: pathos\n",
      "    Found existing installation: pathos 0.3.2\n",
      "    Uninstalling pathos-0.3.2:\n",
      "      Successfully uninstalled pathos-0.3.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: humbug\n",
      "    Found existing installation: humbug 0.3.2\n",
      "    Uninstalling humbug-0.3.2:\n",
      "      Successfully uninstalled humbug-0.3.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.24.5\n",
      "    Uninstalling huggingface-hub-0.24.5:\n",
      "      Successfully uninstalled huggingface-hub-0.24.5\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.6.7\n",
      "    Uninstalling dataclasses-json-0.6.7:\n",
      "      Successfully uninstalled dataclasses-json-0.6.7\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.131\n",
      "    Uninstalling botocore-1.34.131:\n",
      "      Successfully uninstalled botocore-1.34.131\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.10.0\n",
      "    Uninstalling aiohttp-3.10.0:\n",
      "      Successfully uninstalled aiohttp-3.10.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.10.2\n",
      "    Uninstalling s3transfer-0.10.2:\n",
      "      Successfully uninstalled s3transfer-0.10.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.38.0\n",
      "    Uninstalling openai-1.38.0:\n",
      "      Successfully uninstalled openai-1.38.0\n",
      "  Attempting uninstall: llama-cloud\n",
      "    Found existing installation: llama-cloud 0.0.11\n",
      "    Uninstalling llama-cloud-0.0.11:\n",
      "      Successfully uninstalled llama-cloud-0.0.11\n",
      "  Attempting uninstall: aiobotocore\n",
      "    Found existing installation: aiobotocore 2.13.1\n",
      "    Uninstalling aiobotocore-2.13.1:\n",
      "      Successfully uninstalled aiobotocore-2.13.1\n",
      "  Attempting uninstall: llama-index-legacy\n",
      "    Found existing installation: llama-index-legacy 0.9.48\n",
      "    Uninstalling llama-index-legacy-0.9.48:\n",
      "      Successfully uninstalled llama-index-legacy-0.9.48\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.59\n",
      "    Uninstalling llama-index-core-0.10.59:\n",
      "      Successfully uninstalled llama-index-core-0.10.59\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.131\n",
      "    Uninstalling boto3-1.34.131:\n",
      "      Successfully uninstalled boto3-1.34.131\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.4.9\n",
      "    Uninstalling llama-parse-0.4.9:\n",
      "      Successfully uninstalled llama-parse-0.4.9\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.1.32\n",
      "    Uninstalling llama-index-readers-file-0.1.32:\n",
      "      Successfully uninstalled llama-index-readers-file-0.1.32\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.1.27\n",
      "    Uninstalling llama-index-llms-openai-0.1.27:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.1.27\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.2.7\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.2.7:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.2.7\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.1.11\n",
      "    Uninstalling llama-index-embeddings-openai-0.1.11:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.1.11\n",
      "  Attempting uninstall: cohere\n",
      "    Found existing installation: cohere 5.6.2\n",
      "    Uninstalling cohere-5.6.2:\n",
      "      Successfully uninstalled cohere-5.6.2\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.1.6\n",
      "    Uninstalling llama-index-readers-llama-parse-0.1.6:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.1.6\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.1.8\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.1.8:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.1.8\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.1.13\n",
      "    Uninstalling llama-index-cli-0.1.13:\n",
      "      Successfully uninstalled llama-index-cli-0.1.13\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.2.9\n",
      "    Uninstalling llama-index-agent-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.2.9\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.208\n",
      "    Uninstalling langchain-0.0.208:\n",
      "      Successfully uninstalled langchain-0.0.208\n",
      "  Attempting uninstall: aioboto3\n",
      "    Found existing installation: aioboto3 13.1.1\n",
      "    Uninstalling aioboto3-13.1.1:\n",
      "      Successfully uninstalled aioboto3-13.1.1\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.1.7\n",
      "    Uninstalling llama-index-program-openai-0.1.7:\n",
      "      Successfully uninstalled llama-index-program-openai-0.1.7\n",
      "  Attempting uninstall: deeplake\n",
      "    Found existing installation: deeplake 3.9.16\n",
      "    Uninstalling deeplake-3.9.16:\n",
      "      Successfully uninstalled deeplake-3.9.16\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.1.3\n",
      "    Uninstalling llama-index-question-gen-openai-0.1.3:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.1.3\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.10.59\n",
      "    Uninstalling llama-index-0.10.59:\n",
      "      Successfully uninstalled llama-index-0.10.59\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchainplus-sdk 0.0.20 requires pydantic<2,>=1, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 SQLAlchemy-2.0.31 aioboto3-13.1.1 aiobotocore-2.13.1 aiofiles-24.1.0 aiohappyeyeballs-2.3.4 aiohttp-3.10.0 aioitertools-0.11.0 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.4.0 async-timeout-4.0.3 attrs-23.2.0 beautifulsoup4-4.12.3 boto3-1.34.131 botocore-1.34.131 certifi-2024.7.4 charset-normalizer-3.3.2 click-8.1.7 cohere-5.6.2 dataclasses-json-0.6.7 deeplake-3.9.16 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 distro-1.9.0 exceptiongroup-1.2.2 fastavro-1.9.5 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.6.1 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 huggingface-hub-0.24.5 humbug-0.3.2 idna-3.7 jmespath-1.0.1 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-core-0.2.28 langchain-text-splitters-0.2.2 langsmith-0.1.96 libdeeplake-0.0.138 llama-cloud-0.0.11 llama-index-0.10.59 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.59 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.27 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.32 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 lz4-4.3.3 marshmallow-3.21.3 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 nest-asyncio-1.6.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 openai-1.38.0 orjson-3.10.6 packaging-24.1 pandas-2.2.2 parameterized-0.9.0 pathos-0.3.2 pillow-10.2.0 pox-0.3.4 ppft-1.7.6.8 pydantic-2.8.2 pydantic-core-2.20.1 pyjwt-2.9.0 pypdf-4.3.1 python-dateutil-2.9.0.post0 pytz-2024.1 regex-2024.7.24 requests-2.32.3 s3transfer-0.10.2 six-1.16.0 sniffio-1.3.1 soupsieve-2.5 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.19.1 tqdm-4.66.4 types-requests-2.32.0.20240712 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.2 wrapt-1.16.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall llama-index deeplake openai cohere langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tjwZjA8-wITr"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "#You can set the logging level to DEBUG for more verbose output,\n",
    "# or use level=logging.INFO for less detailed information.\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLUDcXpI41Q_"
   },
   "source": [
    "# LlamaHub Wikipedia Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhaDzVaxwIRD",
    "outputId": "fc9cb5c0-c1b3-4641-c37c-77a93ff5eba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53213/167685543.py:3: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "  WikipediaReader = download_loader(\"WikipediaReader\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-wikipedia in ./.conda/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.conda/lib/python3.10/site-packages (from llama-index-readers-wikipedia) (0.10.59)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.10.0)\n",
      "Requirement already satisfied: dataclasses-json in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.6.1)\n",
      "Requirement already satisfied: httpx in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.38.0)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.0.3)\n",
      "Requirement already satisfied: click in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.7.24)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.readers.download import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "\n",
    "loader = WikipediaReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Z35ot7P1wIO0"
   },
   "outputs": [],
   "source": [
    "documents = loader.load_data(pages=['Nicolas Maduro', 'Maria Corina Machado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i9Zp6BJwILk",
    "outputId": "f7ade60f-631a-4b51-981a-26fda4f7c4a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( documents )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='5791389', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='María Corina Machado Parisca (born 7 October 1967) is a Venezuelan opposition politician and industrial engineer who served as an elected member of the National Assembly of Venezuela from 2011 to 2014. Machado entered politics in 2002 as the founder and leader of the vote-monitoring group Súmate, alongside Alejandro Plaz. In 2018, she was listed as one of BBC\\'s 100 Women. Machado is currently regarded as a leading figure of the Venezuelan opposition; the Nicolás Maduro government in Venezuela has banned Machado from leaving Venezuela. \\nMachado was a candidate in the 2012 Venezuelan presidential election but lost the opposition primary to Henrique Capriles. During the 2014 Venezuelan protests, Machado was one of the lead figures in organizing protests against the government of Nicolás Maduro. In 2019, amid the Venezuelan presidential crisis, she announced that she would launch a second presidential run if disputed interim President Juan Guaidó successfully called for an election; Guaidó was ultimately unsuccessful in his efforts. \\nShe was a precandidate for Vente Venezuela in the primary elections of the Unitary Platform of 2023, although on 30 June 2023 she was disqualified for fifteen years by the Comptroller General of Venezuela. Her disqualification was confirmed by the Supreme Court of Justice of Venezuela in January 2024. After winning the primary elections, Machado was declared the opposition candidate for the 2024 presidential elections, though she was replaced by Corina Yoris on 22 March 2024. Yoris was prevented from registering as a candidate and was temporarily replaced by Edmundo González Urrutia.\\nOn 1 August 2024, Machado published a letter in The Wall Street Journal, stating that she had gone in to hiding \"fearing for my life, my freedom, and that of my fellow countrymen from the dictatorship of Nicolás Maduro\".\\n\\n\\n== Early life and education ==\\nMachado was born in Caracas, Venezuela, on 7 October 1967. The oldest of four sisters, she is the daughter of Henrique Machado Zuloaga, a prominent steel businessman and Corina Parisca, a psychologist. Her ancestors included Eduardo Blanco, the author of the 1881 classic Venezuela Heroica and a relative who was killed in an uprising against Venezuelan dictator Juan Vicente Gómez.\\nMachado has a degree in industrial engineering from Andrés Bello Catholic University and a master\\'s degree in finance from Instituto de Estudios Superiores de Administración (IESA, business school) in Caracas. She was also part of Yale University\\'s World Fellows Program in 2009.\\nIn 1992, as a mother of three, Machado started Fundación Atenea (Atenea Foundation), a foundation using private donations to care for orphaned and delinquent Caracas street children; she also served as chair of the Opportunitas Foundation. After working in the auto industry in Valencia she moved in 1993 to Caracas. Because of her role in Súmate, Machado left the foundation so that it would not be politicized.\\n\\n\\n== Súmate ==\\n\\nThe founding of Venezuelan volunteer civil organization Súmate resulted from a hurried encounter between Machado and Alejandro Plaz in a hotel lobby in 2001, where they shared their concern about the course that was being shaped for Venezuela. Machado said: \"Something clicked. I had this unsettling feeling that I could not stay at home and watch the country get polarized and collapse ... We had to keep the electoral process but change the course, to give Venezuelans the chance to count ourselves, to dissipate tensions before they built up. It was a choice of ballots over bullets.\"\\nSúmate led a petition drive for the 2004 Venezuelan recall referendum of Hugo Chávez, then president of Venezuela. According to CBS News, Chávez branded the leaders of Súmate as conspirators, coup plotters, and lackeys of the U.S. government. After the referendum, members of Súmate were charged with treason and conspiracy, under Article 132 of the Venezuelan Penal Code, for receiving financial support for their activities from the National Endowment for Democracy (NED). In 2005, Machado faced conspiracy charge stemming from the $31,000 grant from the NED for \"non-partisan educational work\". That same year, The New York Times said she was \"the Venezuelan government\\'s most detested adversary, a young woman with a quick wit and machine-gun-fast delivery who often appears in Washington or Madrid to denounce what she calls the erosion of democracy under President Hugo Chávez\", and stated the Venezuelan government considers her \"a member of a corrupt elite that is doing the bidding of the much reviled Bush administration\".\\nA U.S. Department of State spokesperson said the decision to prosecute her was \"part of President Hugo Chávez\\'s campaign ... aimed at frightening members of civil society and preventing them from exercising their democratic rights\", adding that the George W. Bush administration was \"seriously concerned\" about the Supreme Tribunal of Justice\\'s (TSJ) decision. The criminal charges triggered condemnation from Human Rights Watch and democracy groups, the U.S. Embassy in Venezuela, and a coalition of world leaders. Machado acknowledged the support of Venezuelans for Chávez, saying: \"We have to recognize the positive things that have been done\", but says that the president is \"increasingly intolerant.\"\\nMachado and Plaz were invited to meet with National Assembly legislators in August 2006 for an investigation about Súmate\\'s funding but were denied access to the hearing, although they say they received two letters requesting their presence. She also faced treason charges for signing the Carmona Decree during the 2002 Venezuelan coup attempt. Machado said that she wrote her name on what she believed to be a sign-in sheet while visiting the presidential palace. The charges carry a penalty of more than a decade in prison; the trial was suspended in February 2006 because of due process violations by the trial judge, and has been postponed.\\n\\n\\n== 2011 presidential candidacy ==\\nIn 2011, Machado launched her candidacy for the 2012 Venezuelan presidential election. The Los Angeles Times said that her name was raised as a potential candidate, and Michael Shifter stated that she was a future presidential contender \"who can effectively communicate a vision for a post-Chávez Venezuela that can appeal to enough Chávez supporters\". According to the Financial Times, Machado was \"dubbed the new face of the opposition ... Even President Hugo Chávez has spoken of confronting her in the 2012 presidential elections.\"\\nOn 13 January 2012, during the annual State of the Nation Speech delivered by Chávez to the Venezuelan National Assembly, Machado confronted him about shortages of basic goods, crime, and nationalizations of basic industries. She said: \"How can you say that you protect private property when you have been expropriating small businesses; expropriating and not paying is stealing.\" The winner of the 2012 primary to be the opposition candidate against Chávez in the October presidential election was Henrique Capriles Radonski; according to the Associated Press, Machado \"conceded defeat before the results were announced, saying she also will actively back Capriles\".\\n\\n\\n== National Assembly ==\\n\\n\\n=== Candidacy ===\\n\\nIn February 2010, Machado resigned from Súmate and announced her candidacy for the National Assembly of Venezuela. She represented Miranda for the Chacao, Baruta, El Hatillo, and the Parroquia Leoncio Martínez de Sucre municipalities.  She was a Justice First (Primero Justicia) party member of the Coalition for Democratic Unity (Mesa de la Unidad Democrática – MUD) in opposition to Chávez\\'s party, the United Socialist Party of Venezuela (Partido Socialista Unido de Venezuela – PSUV). In announcing her candidacy, she said Venezuelans were good, decent, and free people who do not want to live with violence or hate; she promised to defend the right for Venezuelans to think freely and live without fear.  In April 2010, Machado won the primary election. She campaigned actively in \"slums once viewed as solid pro-Chávez territory\", attempting to \"capitalize on domestic problems, including widespread violent crime, power outages in some regions, a severe housing shortage and 30-percent inflation\".\\nMachado complained that MUD candidates faced \"what she called a government-orchestrated propaganda machine that churns out spots ridiculing Chávez\\'s critics, runs talk shows dominated by ruling party hopefuls and picks up all of the president\\'s speeches\", and that she had to campaign with less funds as she \"struggled to convince supporters and business leaders to contribute to her campaign because they fear reprisals by the government and Chávez-friendly prosecutors\". According to The Economist, Venezuela\\'s constitution \"prohibits government officials, including the president, from using their position to favour a political tendency. But the electoral authority, whose board comprises four chavistas and a lone oppositionist, says they can do it anyway.\"\\nChávez was accused of breaking campaign laws by using state-run television to \"berate rivals and praise friends\" during the election campaign; he denied breaking the law, and suggested that the only director of the National Election Council\\'s five directors who is not pro-Chávez and who raised the issue could be prosecuted for making the charges. According to a reporter for the Associated Press, Venezuela\\'s electoral council \"has for years ignored laws that bar the president and other elected officials from actively campaigning for candidates. Chavez ... has threatened legal action against Vicente Diaz, the lone member of the electoral council who has criticized his heavy use of state media ahead of the vote.\" Machado said: \"While we are visiting voters, going from house to house, the ruling party\\'s campaign is imposed through televised speeches.\" When the state-run television channel interviewed Machado, they ran images of her Oval Office meeting in 2005 with George W. Bush, described by an Associated Press reporter as \"Chavez\\'s longtime nemesis\". She said: \"We have a campaign led by the PSUV with a lot of resources that we know are public resources – even when the constitution prohibits it. The PSUV benefitted from frequent cadenas (Chávez speeches that every Venezuelan TV channel are mandated to run), while \"the main government channel air[ed] a steady stream of rallies and ads featuring Chavez\\'s red-clad candidates\". When Machado was interviewed by the state-run channel, the interview was \"abruptly cut off\" and \"shifted to a campaign rally where Chávez spoke to a theater filled with supporters\".\\n\\n\\n=== Election ===\\nMachado won the election to the National Assembly on 25 September 2010, as the highest vote-getter in the nation; she and fellow Justice First Miranda candidate Enrique Mendoza were the \"two highest vote-getters nationwide\". Machado said the president \"made a big mistake by turning the election into a plebiscite on himself ... This is a clear signal that Venezuelans do not want an authoritarian government, a militarized government, a centralized government and a government that wants to turn Venezuela into Cuba ... A new phase begins today, and we\\'ve taken a big step toward the day when democratic values, freedom, justice and good governance prevail.\" She added: \"We now have the legitimacy of the citizen vote. We are the representatives of the people.\" She concluded: \"It is very clear. Venezuela said no to Cuban-like communism.\"\\n\\n\\n=== Removal ===\\nOn 21 March 2014, Machado appeared as an alternate envoy at the request of Panama at the Organization of American States (OAS), amid the protests in Venezuela, to speak about the situation in Venezuela. According to The Wall Street Journal, following her appearance at the OAS, \"pro-Maduro parliamentarians, who dominate the National Assembly\", claimed her appearance at the OAS was prohibited by Venezuela\\'s constitution, and removed her from the National Assembly. Machado responded by accusing Diosdado Cabello (president of the National Assembly) of having a \"dictatorship in the National Assembly\", and said that her removal from the National Assembly was illegal.\\n\\n\\n== 2014 protests ==\\n\\nMachado was among the leaders of the opposition demonstrations against Nicolás Maduro in the 2014 Venezuelan protests. Venezuela\\'s Congress on 18 March 2014 requested a criminal investigation of Machado for crimes including treason for her involvement in the anti-government protests. Machado responded to the accusations saying: \"In a dictatorship, the weaker the regime is, the greater the repression.\" After her removal on 21 March 2014, Machado, along with supporters, began a march on 1 April 2014 toward downtown Caracas protesting against Machado\\'s expulsion, where Machado attempted to return to her seat in the National Assembly. The demonstrators were prevented from leaving by the National Guard, which dispersed them with tear gas.\\nIn May 2014, Venezuelan government official Jorge Rodríguez presented allegations of a plot by opposition politicians and officials, including Machado, to overthrow the Maduro\\'s government. The evidence provided by the Venezuelan government were alleged emails through Google that were addressed to others from both Machado and Pedro Mario Burelli. Burelli responded that the emails were falsified by the Bolivarian Intelligence Service (SEBIN), showing what he said were the original emails. In June 2014, Venezuela\\'s attorney general Luisa Ortega Díaz subpoenaed Machado along with Burelli, Diego Arria, and Ricardo Koesling. By 11 June 2014, arrest warrants were issued. Burelli hired Kivu, a U.S.-based cybersecurity company, to analyze the alleged emails. Kivu concluded that there was \"no evidence of the existence of any emails between Pedro Burelli\\'s Google email accounts and the alleged recipients\", that the alleged emails presented by the Venezuelan government had \"many indications of user manipulation\" and that \"Venezuelan officials used forged emails to accuse government adversaries of plotting to kill President Nicolas Maduro\".\\nIn November 2014, government officials announced that Machado was to be formally charged on 3 December 2014. Machado and others stated that the accusations were false and were created by the Venezuelan government to deflect attention from Venezuela\\'s economic problems and polls showing Maduro\\'s approval rating at a record low of 30%.\\n\\n\\n== Later political career ==\\nOn 1 February 2019, Machado announced her intent to run for president if Juan Guaidó calls elections, owing to the 2019 Venezuelan presidential crisis. For the next Venezuelan presidential election, Machado was recognized as a front-running opposition candidate. In an interview discussing the election, Machado insisted that she was not interested in the opposition primary and said that \"my goal is to get Maduro out and be able to defeat the regime using all the force.\"  She argued: \"There are only two options here, ... We win with a huge majority or Maduro steals the election.\" According to head of the Delphos pollster Félix Seijas, \"[t]he opposition as it existed is no longer, and that opens the door for her to capture support beyond her radical base\", while explaining her expanded support. On 30 June 2023, she was reportedly disqualified from holding office for 15 years by the government due to her leadership in anti-government protests.\\n\\n\\n=== 2023 presidential primary elections ===\\nOn 14 August 2022, Machado confirmed her participation in the 2023 Unitary Platform presidential primaries. During the primaries, Machado positioned herself against the technical assistance of the National Electoral Council (CNE) in the election, alleging that CNE is part of a \"criminal system. In the same way, she  defended the return to manual voting. On 15 March 2023, she officially began her campaign tour of the country, in the State of Mérida. During her pre-campaign, Machado maintained criticism towards the traditional opposition leadership, mainly the Democratic Action, Justice First, A New Era, and Popular Will parties. She also made it clear that she was willing to negotiate an exit from Chavismo to achieve a transition.\\nOn 30 June 2023, she was disqualified for fifteen years by the Comptroller General of Venezuela, after a request from the politician José Brito. The comptroller linked her to alleged crimes by Juan Guaidó and accused her of supporting sanctions during the Venezuelan crisis. Analysts determined that the accusation of having participated in the interim was incoherent, taking into account that she was not a member of the 2015 opposition National Assembly (being prevented by a disqualification from the Comptroller\\'s Office), in addition to never having been appointed in any position in Guaidó\\'s interim government. Organizations like the United Nations, the Organization of American States, and the European Union, as well as countries such as Colombia, Paraguay, Uruguay, Ecuador, United States, United Kingdom, Germany, Chile, Canada, and France, rejected the disqualification of Machado. The European Union Parliament called the ban \"arbitrary and politically fabricated\", and the Associated Press stated the banning opposing politicians from elections is a frequent tactic used by the government.\\nOn 26 October 2023, after winning the primary elections, the National Primary Commission proclaimed Machado as the unitary presidential candidate of the opposition.\\nMachado\\'s 15-year disqualification was confirmed by the Supreme Court of Justice of Venezuela in January 2024. The court said the disqualification was \"for being involved... in the corruption plot orchestrated by the usurper Juan Guaido\", which had led to a \"criminal blockade of the Bolivarian Republic of Venezuela, as well as the shameless dispossession of the companies and wealth of the Venezuelan people abroad, with the complicity of corrupt governments\".\\nMachado named Corina Yoris as her alternate. Yoris was unable to register as a candidate and named Edmundo González Urrutia as her temporary replacement.\\n\\n\\n=== 2024 presidential election ===\\n\\nEven though Machado is not the presidential candidate, she has remained the leader of the opposition to Chavismo during the electoral process. \\u200bThe majority support that candidate Edmundo González receives in various polls is due to the boost given to him by the Machado support.\\nRegarding the role that Machado will play in a hypothetical González Urrutia government, The Telegraph comments \"Should the opposition win, Ms Machado is widely expected to be the de facto leader of a government formally led by Mr González\". The newspaper also compared the massive popular movement around Machado, with the rise of Hugo Chávez to the presidency in 1998, in terms of the \"fervor\" it generates in citizens, both in a context of political crisis and decadence of the system.\\nOn July 4, González and Machado officially began the electoral campaign along with other opposition leaders. The event, which was planned to be a caravan from Chacaíto to El Marqués, became a march with the attendance of dozens of thousands of people.\\nThe New York Times, referring to Machado, described her as \"an energetic former legislator whose central message is the promise of bringing Venezuelans home by restoring democracy and getting the economy going again\".\\nOn 1 August, Machado published a letter in The Wall Street Journal, stating that she had gone in to hiding \"fearing for my life, my freedom, and that of my fellow countrymen from the dictatorship of Nicolás Maduro\"; in the letter, she laid out the evidence she said she had from the vote tallies supporting PUD\\'s win, and stated that Maduro had expelled witnesses from the polls, while the witnesses \"protected the voter receipts with their lives throughout the night\" of the elections.\\n\\n\\n== Political views ==\\nMachado is anti-chavismo and has disagreed with other sections of the Venezuelan opposition. In 2011, she campaigned as a promotor of \"popular capitalism\". Machado supports the privatization of state-run entities in Venezuela, including oil company PDVSA. Machado has supported the international sanctions during the Venezuelan crisis, and has advocated for foreign intervention to remove Maduro on humanitarian grounds. In 2023, she ran as a candidate in the opposition presidential primaries. The authoritarian Maduro regime subsequently barred her from running. She subsequently became the main driving force for the main opposition candidate, Edmundo González, who was allowed to compete by the Maduro regime.\\nShe has described herself as a centrist liberal, saying in an interview with El Estímulo that the categories of left and right were invented by Marxists and that she is the only non-socialist politician in the Venezuelan political spectrum. Machado said: \"We are a centre liberal party, so they say it is from the extreme right, because for the Marxists if you are not from the left you are from the ultra right, but Vente is a party of centre liberals.\" She also stated that the division of the country and life between rich and poor sought to manipulate, simplify and appeal to populism as a control of the person and the individual. Machado has been described as a radical and a right-wing politician.\\nDomestically, Machado has called for the banning of reelection to political offices in Venezuela, is in favor of same-sex marriage in Venezuela, supports the legalization of medical cannabis, and has called on a national debate regarding the legality of abortion. She believes that those who have more, should give more, and defended the saying that \"being rich is good\"; she criticized Hugo Chávez, saying that \"Chávez was the president of the poor, yes, very poor that he loved them, because there is no more effective way to control a society than to subject it to dependency. Dying with outstretched hand.\"\\nIn a 2024 interview Machado talked of making education available for all Venezualans, and of reforming the Venezualan judiciary.\\n\\n\\n== Target of violence ==\\nDescribed as a Lady of Steel, or Iron Lady, The New York Times states that supporters see her as \"courageous for staying in Venezuela when many other politicians have fled\".\\nWhile attending the bicentennial celebration of Venezuela\\'s Declaration of Independence on 5 July 2011, following controversial comments made earlier by Machado about Venezuela\\'s dependency on Cuba and not being independent, Machado was attacked by an angry group of Venezuelan government supporters. The group of about 50 threw stones and bottles at her; authorities defended her, and one officer was injured, as Machado was evacuated from the area by a police motorbike. Machado later thanked the authorities for defending her and apologized for any of their injuries. \\nDuring Machado\\'s presidential race in 2011, she and her companions were attacked on 16 October by a small group of the Motorized Front of the PSUV while in Turmero, injuring Machado and two others. The group attacked them with kicks, punches and objects while saying \"this is chavista territory, no political opposition enters here\".\\nOn 30 April 2013, cameras covering the National Assembly were turned to the ceiling and opposition members stated they were attacked and assaulted in an \"ambush by supporters of President Nicolas Maduro\\'s government\". Machado was injured, along with other legislators in the National Assembly, saying she was attacked from behind, hit in the face and kicked while on the floor which left her with a broken nose. Machado said the brawl \"was a premeditated, cowardly, vile, aggression\". Maduro responded to the situation by saying: \"What happened today in the National Assembly, we do not agree with violence. They tell us and we knew that the opposition was coming to provoke violence.\" No disciplinary actions was taken against any of the attackers after the incident.\\nAt a rally on 16 November 2013 showing support for the opposition party during municipal elections, Machado and other politicians were attacked by government supporters, with stones and fireworks. \\nAfter leading protests in Bolivar state on 14 March 2014, Machado, the Bishop of Ciudad Guayana, Mariano Parra, and other citizens in the area were attacked at the Puerto Ordaz airport. The National Guard intervened to disperse the attack. \\nWhile heading to a meeting in Caricuao on 30 July 2014, members of colectivos attacked Machado. The vehicle Machado was traveling in was heavily damaged, with the body and windows of the vehicle being struck with gun handles, sticks and stones. Machado escaped and was then moved to the assembly place while colectivos followed breaking down the door where they then left the scene after confrontations with residents protecting Machado.\\n\\n\\n== Awards and recognition ==\\n\\nIn May 2005, the then U.S. president George W. Bush welcomed Machado to the Oval Office. After meeting with Machado and discussing Súmate\\'s \"efforts to safeguard the integrity and transparency of Venezuela\\'s electoral process\", a White House spokesperson said, \"[t]he President expressed his concerns about efforts to harass and intimidate Súmate and its leadership\". Machado was hailed by National Review in 2006 as \"the best of womankind and the difficult times many women face around the globe\" on a list of Women the World Should Know for International Women\\'s Day.\\nIn 2009, Machado was chosen out of 900 applicants as one of 15 accepted to the Yale World Fellows Program. The Yale University program \"aim[s] to build a global network of emerging leaders and to broaden international understanding worldwide. ... \\'Each of the 2009 Yale World Fellows has demonstrated an outstanding record of accomplishment and unlimited potential for future success,\\' said Program Director Michael Cappello.\" The Yale World Fellows Program press release said: \"Machado devotes herself to defending democratic institutions and civil liberties through SUMATE, the nation\\'s leading watchdog for electoral transparency.\" Machado would later graduate from the program.\\n\\n\\n=== Awards ===\\n2015, Cádiz Cortes Ibero-American Freedom Prize, which was awarded \"given the unblemished defense of freedom in your community and minimum requirements of the realization of human rights in the same, which has led them to be subject to public rebuke of their government, including the flagrant situation of imprisonment or the cutting of your minimal civil rights.\"\\n2018, BBC\\'s 100 Most Influential Women.\\n2019, Prize for Freedom from Liberal International.\\n\\n\\n== Personal life ==\\nMachado is divorced and has three children; her children live abroad as Machado says their lives have been threatened.\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nTurkewitz, Julie; Herrera, Isayen (24 July 2024). \"The \\'Iron Lady\\' of Venezuela Threatens to Unseat Its Autocrat\". The New York Times.\\n\\n\\n== External links ==\\n\\nOfficial Súmate website\\nMaria Corina Machado\\'s Flickr photostream\\n2010 Election website', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03lff4VUTaN9"
   },
   "source": [
    "# Save on DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-deeplake\n",
      "  Using cached llama_index_vector_stores_deeplake-0.1.5-py3-none-any.whl.metadata (711 bytes)\n",
      "Collecting deeplake>=3.9.12 (from llama-index-vector-stores-deeplake)\n",
      "  Using cached deeplake-3.9.16-py3-none-any.whl\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-vector-stores-deeplake)\n",
      "  Downloading llama_index_core-0.10.60-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting numpy<2.0 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pillow~=10.2.0 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting boto3 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached boto3-1.34.153-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting click (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pathos (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting humbug>=0.3.1 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached humbug-0.3.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting tqdm (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting lz4 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting pyjwt (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pydantic (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting libdeeplake==0.0.138 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached libdeeplake-0.0.138-cp310-cp310-manylinux2014_x86_64.whl.metadata (352 bytes)\n",
      "Collecting aioboto3>=10.4.0 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached aioboto3-13.1.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting nest-asyncio (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting dill (from libdeeplake==0.0.138->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached aiohttp-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pandas (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aiobotocore==2.13.1 (from aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached aiobotocore-2.13.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting aiofiles>=23.2.1 (from aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting botocore<1.34.132,>=1.34.70 (from aiobotocore==2.13.1->aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached botocore-1.34.131-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.13.1->aiobotocore[boto3]==2.13.1->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached aioitertools-0.11.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting boto3 (from deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached boto3-1.34.131-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached aiohappyeyeballs-2.3.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting packaging>=17.0 (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-deeplake)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached llama_index_vector_stores_deeplake-0.1.5-py3-none-any.whl (5.0 kB)\n",
      "Using cached libdeeplake-0.0.138-cp310-cp310-manylinux2014_x86_64.whl (16.8 MB)\n",
      "Downloading llama_index_core-0.10.60-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached aioboto3-13.1.1-py3-none-any.whl (34 kB)\n",
      "Using cached aiobotocore-2.13.1-py3-none-any.whl (76 kB)\n",
      "Using cached aiohttp-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached boto3-1.34.131-py3-none-any.whl (139 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached humbug-0.3.2-py3-none-any.whl (15 kB)\n",
      "Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached openai-1.38.0-py3-none-any.whl (335 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "Using cached PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiohappyeyeballs-2.3.4-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached botocore-1.34.131-py3-none-any.whl (12.3 MB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Using cached ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "Using cached s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, sniffio, six, regex, PyYAML, pyjwt, ppft, pox, pillow, packaging, numpy, networkx, nest-asyncio, mypy-extensions, multidict, lz4, joblib, jmespath, idna, h11, greenlet, fsspec, frozenlist, exceptiongroup, distro, dill, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aioitertools, aiohappyeyeballs, aiofiles, yarl, typing-inspect, SQLAlchemy, requests, python-dateutil, pydantic-core, nltk, multiprocess, marshmallow, libdeeplake, httpcore, deprecated, anyio, aiosignal, tiktoken, pydantic, pathos, pandas, humbug, httpx, dataclasses-json, botocore, aiohttp, s3transfer, openai, aiobotocore, llama-index-core, boto3, aioboto3, deeplake, llama-index-vector-stores-deeplake\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: dirtyjson\n",
      "    Found existing installation: dirtyjson 1.0.8\n",
      "    Uninstalling dirtyjson-1.0.8:\n",
      "      Successfully uninstalled dirtyjson-1.0.8\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.1\n",
      "    Uninstalling tzdata-2024.1:\n",
      "      Successfully uninstalled tzdata-2024.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.5.0\n",
      "    Uninstalling tenacity-8.5.0:\n",
      "      Successfully uninstalled tenacity-8.5.0\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.1\n",
      "    Uninstalling sniffio-1.3.1:\n",
      "      Successfully uninstalled sniffio-1.3.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.7.24\n",
      "    Uninstalling regex-2024.7.24:\n",
      "      Successfully uninstalled regex-2024.7.24\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: pyjwt\n",
      "    Found existing installation: PyJWT 2.9.0\n",
      "    Uninstalling PyJWT-2.9.0:\n",
      "      Successfully uninstalled PyJWT-2.9.0\n",
      "  Attempting uninstall: ppft\n",
      "    Found existing installation: ppft 1.7.6.8\n",
      "    Uninstalling ppft-1.7.6.8:\n",
      "      Successfully uninstalled ppft-1.7.6.8\n",
      "  Attempting uninstall: pox\n",
      "    Found existing installation: pox 0.3.4\n",
      "    Uninstalling pox-0.3.4:\n",
      "      Successfully uninstalled pox-0.3.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.3\n",
      "    Uninstalling networkx-3.3:\n",
      "      Successfully uninstalled networkx-3.3\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 1.0.0\n",
      "    Uninstalling mypy-extensions-1.0.0:\n",
      "      Successfully uninstalled mypy-extensions-1.0.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.5\n",
      "    Uninstalling multidict-6.0.5:\n",
      "      Successfully uninstalled multidict-6.0.5\n",
      "  Attempting uninstall: lz4\n",
      "    Found existing installation: lz4 4.3.3\n",
      "    Uninstalling lz4-4.3.3:\n",
      "      Successfully uninstalled lz4-4.3.3\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.0.3\n",
      "    Uninstalling greenlet-3.0.3:\n",
      "      Successfully uninstalled greenlet-3.0.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.1\n",
      "    Uninstalling frozenlist-1.4.1:\n",
      "      Successfully uninstalled frozenlist-1.4.1\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.2.2\n",
      "    Uninstalling exceptiongroup-1.2.2:\n",
      "      Successfully uninstalled exceptiongroup-1.2.2\n",
      "  Attempting uninstall: distro\n",
      "    Found existing installation: distro 1.9.0\n",
      "    Uninstalling distro-1.9.0:\n",
      "      Successfully uninstalled distro-1.9.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.7.4\n",
      "    Uninstalling certifi-2024.7.4:\n",
      "      Successfully uninstalled certifi-2024.7.4\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.2.0\n",
      "    Uninstalling attrs-23.2.0:\n",
      "      Successfully uninstalled attrs-23.2.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 4.0.3\n",
      "    Uninstalling async-timeout-4.0.3:\n",
      "      Successfully uninstalled async-timeout-4.0.3\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "  Attempting uninstall: aioitertools\n",
      "    Found existing installation: aioitertools 0.11.0\n",
      "    Uninstalling aioitertools-0.11.0:\n",
      "      Successfully uninstalled aioitertools-0.11.0\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.3.4\n",
      "    Uninstalling aiohappyeyeballs-2.3.4:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.3.4\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 24.1.0\n",
      "    Uninstalling aiofiles-24.1.0:\n",
      "      Successfully uninstalled aiofiles-24.1.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.4\n",
      "    Uninstalling yarl-1.9.4:\n",
      "      Successfully uninstalled yarl-1.9.4\n",
      "  Attempting uninstall: typing-inspect\n",
      "    Found existing installation: typing-inspect 0.9.0\n",
      "    Uninstalling typing-inspect-0.9.0:\n",
      "      Successfully uninstalled typing-inspect-0.9.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.31\n",
      "    Uninstalling SQLAlchemy-2.0.31:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.31\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.21.3\n",
      "    Uninstalling marshmallow-3.21.3:\n",
      "      Successfully uninstalled marshmallow-3.21.3\n",
      "  Attempting uninstall: libdeeplake\n",
      "    Found existing installation: libdeeplake 0.0.138\n",
      "    Uninstalling libdeeplake-0.0.138:\n",
      "      Successfully uninstalled libdeeplake-0.0.138\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: deprecated\n",
      "    Found existing installation: Deprecated 1.2.14\n",
      "    Uninstalling Deprecated-1.2.14:\n",
      "      Successfully uninstalled Deprecated-1.2.14\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.4.0\n",
      "    Uninstalling anyio-4.4.0:\n",
      "      Successfully uninstalled anyio-4.4.0\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "  Attempting uninstall: pathos\n",
      "    Found existing installation: pathos 0.3.2\n",
      "    Uninstalling pathos-0.3.2:\n",
      "      Successfully uninstalled pathos-0.3.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: humbug\n",
      "    Found existing installation: humbug 0.3.2\n",
      "    Uninstalling humbug-0.3.2:\n",
      "      Successfully uninstalled humbug-0.3.2\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.6.7\n",
      "    Uninstalling dataclasses-json-0.6.7:\n",
      "      Successfully uninstalled dataclasses-json-0.6.7\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.131\n",
      "    Uninstalling botocore-1.34.131:\n",
      "      Successfully uninstalled botocore-1.34.131\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.10.0\n",
      "    Uninstalling aiohttp-3.10.0:\n",
      "      Successfully uninstalled aiohttp-3.10.0\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.10.2\n",
      "    Uninstalling s3transfer-0.10.2:\n",
      "      Successfully uninstalled s3transfer-0.10.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.38.0\n",
      "    Uninstalling openai-1.38.0:\n",
      "      Successfully uninstalled openai-1.38.0\n",
      "  Attempting uninstall: aiobotocore\n",
      "    Found existing installation: aiobotocore 2.13.1\n",
      "    Uninstalling aiobotocore-2.13.1:\n",
      "      Successfully uninstalled aiobotocore-2.13.1\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.59\n",
      "    Uninstalling llama-index-core-0.10.59:\n",
      "      Successfully uninstalled llama-index-core-0.10.59\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.131\n",
      "    Uninstalling boto3-1.34.131:\n",
      "      Successfully uninstalled boto3-1.34.131\n",
      "  Attempting uninstall: aioboto3\n",
      "    Found existing installation: aioboto3 13.1.1\n",
      "    Uninstalling aioboto3-13.1.1:\n",
      "      Successfully uninstalled aioboto3-13.1.1\n",
      "  Attempting uninstall: deeplake\n",
      "    Found existing installation: deeplake 3.9.16\n",
      "    Uninstalling deeplake-3.9.16:\n",
      "      Successfully uninstalled deeplake-3.9.16\n",
      "  Attempting uninstall: llama-index-vector-stores-deeplake\n",
      "    Found existing installation: llama-index-vector-stores-deeplake 0.1.5\n",
      "    Uninstalling llama-index-vector-stores-deeplake-0.1.5:\n",
      "      Successfully uninstalled llama-index-vector-stores-deeplake-0.1.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.0.208 requires dataclasses-json<0.6.0,>=0.5.7, but you have dataclasses-json 0.6.7 which is incompatible.\n",
      "langchain 0.0.208 requires pydantic<2,>=1, but you have pydantic 2.8.2 which is incompatible.\n",
      "langchainplus-sdk 0.0.20 requires pydantic<2,>=1, but you have pydantic 2.8.2 which is incompatible.\n",
      "llama-index 0.10.59 requires llama-index-core==0.10.59, but you have llama-index-core 0.10.60 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 SQLAlchemy-2.0.31 aioboto3-13.1.1 aiobotocore-2.13.1 aiofiles-24.1.0 aiohappyeyeballs-2.3.4 aiohttp-3.10.0 aioitertools-0.11.0 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.4.0 async-timeout-4.0.3 attrs-23.2.0 boto3-1.34.131 botocore-1.34.131 certifi-2024.7.4 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.7 deeplake-3.9.16 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 distro-1.9.0 exceptiongroup-1.2.2 frozenlist-1.4.1 fsspec-2024.6.1 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 humbug-0.3.2 idna-3.7 jmespath-1.0.1 joblib-1.4.2 libdeeplake-0.0.138 llama-index-core-0.10.60 llama-index-vector-stores-deeplake-0.1.5 lz4-4.3.3 marshmallow-3.21.3 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 nest-asyncio-1.6.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 openai-1.38.0 packaging-24.1 pandas-2.2.2 pathos-0.3.2 pillow-10.2.0 pox-0.3.4 ppft-1.7.6.8 pydantic-2.8.2 pydantic-core-2.20.1 pyjwt-2.9.0 python-dateutil-2.9.0.post0 pytz-2024.1 regex-2024.7.24 requests-2.32.3 s3transfer-0.10.2 six-1.16.0 sniffio-1.3.1 tenacity-8.5.0 tiktoken-0.7.0 tqdm-4.66.4 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.2 wrapt-1.16.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip install --upgrade --force-reinstall llama-index-vector-stores-deeplake\n",
    "# %pip install llama-index-llms-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eo8CTHSFTcaR",
    "outputId": "adbf0c99-61ec-4879-eede-15d7cd7e8d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "\n",
    "my_activeloop_org_id = \"macayaven\"\n",
    "my_activeloop_dataset_name = \"LlamaIndex_intro\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "# Create an index over the documents\n",
    "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eWFtVpM_TcTQ"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3GCf8LrULIW",
    "outputId": "9e40d8fb-5863-4de0-c49c-f593463a2c0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:08<00:00,  2.95it/s]\n",
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://macayaven/LlamaIndex_intro', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (25, 1)      str     None   \n",
      " metadata     json      (25, 1)      str     None   \n",
      " embedding  embedding  (25, 1536)  float32   None   \n",
      "    id        text      (25, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkKPAnIl44ss"
   },
   "source": [
    "# Create Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eB6Rc0U0wII_",
    "outputId": "263fa567-a121-49f3-e196-c9ddd40b201b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "# Assuming documents have already been loaded\n",
    "\n",
    "# Initialize the parser\n",
    "parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=20)\n",
    "\n",
    "# Parse documents into nodes\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "print( len( nodes ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCgdd197CTDt"
   },
   "source": [
    "# Create index from Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "G7BdNn-Q5AlG",
    "outputId": "2f78963e-830e-45bd-c6f8-50a99be55cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "- Candidate A has been criticized for human rights violations and violent methods used by security forces during their presidency.\n",
      "- Candidate B has faced economic decline and criticism for focusing more on consolidating power rather than implementing a strategic vision for the country.\n",
      "- Candidate A has faced international condemnation and sanctions, while Candidate B has shown some willingness to change economic policies in response to international pressure.\n",
      "- Candidate A has been accused of authoritarian tendencies and repression of opposition, while Candidate B has shown some willingness to engage in diplomatic relations with various countries.\n",
      "\n",
      "In summary, considering the goal of making Venezuela a great country again, Candidate B may be a better choice as they have shown some flexibility in economic policies and engagement with the international community, which could potentially lead to improvements in the country's situation.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.indices import GPTVectorStoreIndex\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Who of the two candidates would be a better president for Venezuela and why? Analize it in bullet points. And end with a summary. The goal is to make Venezuela a great country again.\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtGKUVg3wI0d"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKHDHMsIwIGp",
    "outputId": "4865ddd8-6d81-4f17-c1b0-a877065d2ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- ------------\n",
      "aioboto3                13.1.1\n",
      "aiobotocore             2.13.1\n",
      "aiofiles                24.1.0\n",
      "aiohttp                 3.9.5\n",
      "aioitertools            0.11.0\n",
      "aiosignal               1.3.1\n",
      "anyio                   4.4.0\n",
      "asttokens               2.4.1\n",
      "async-timeout           4.0.3\n",
      "attrs                   23.2.0\n",
      "backoff                 2.2.1\n",
      "beautifulsoup4          4.12.3\n",
      "boto3                   1.34.131\n",
      "botocore                1.34.131\n",
      "certifi                 2024.7.4\n",
      "charset-normalizer      3.3.2\n",
      "click                   8.1.7\n",
      "cohere                  4.37\n",
      "comm                    0.2.2\n",
      "cssselect               1.2.0\n",
      "dataclasses-json        0.5.14\n",
      "debugpy                 1.6.7\n",
      "decorator               5.1.1\n",
      "deeplake                3.8.8\n",
      "Deprecated              1.2.14\n",
      "dill                    0.3.8\n",
      "distro                  1.9.0\n",
      "exceptiongroup          1.2.2\n",
      "executing               2.0.1\n",
      "fastavro                1.9.5\n",
      "feedfinder2             0.0.4\n",
      "feedparser              6.0.11\n",
      "filelock                3.15.4\n",
      "frozenlist              1.4.1\n",
      "fsspec                  2024.6.1\n",
      "greenlet                3.0.3\n",
      "h11                     0.14.0\n",
      "httpcore                1.0.5\n",
      "httpx                   0.27.0\n",
      "humbug                  0.3.2\n",
      "idna                    3.7\n",
      "importlib-metadata      6.11.0\n",
      "ipykernel               6.29.5\n",
      "ipython                 8.26.0\n",
      "jedi                    0.19.1\n",
      "jieba3k                 0.35.1\n",
      "jmespath                1.0.1\n",
      "joblib                  1.4.2\n",
      "jupyter_client          8.6.2\n",
      "jupyter_core            5.7.2\n",
      "langchain               0.0.208\n",
      "langchainplus-sdk       0.0.20\n",
      "libdeeplake             0.0.90\n",
      "llama-index             0.9.14.post3\n",
      "lxml                    5.2.2\n",
      "lxml_html_clean         0.2.0\n",
      "lz4                     4.3.3\n",
      "marshmallow             3.21.3\n",
      "matplotlib-inline       0.1.7\n",
      "multidict               6.0.5\n",
      "multiprocess            0.70.16\n",
      "mypy-extensions         1.0.0\n",
      "nest_asyncio            1.6.0\n",
      "newspaper3k             0.2.8\n",
      "nltk                    3.8.1\n",
      "numexpr                 2.10.1\n",
      "numpy                   1.26.4\n",
      "openai                  1.3.8\n",
      "openapi-schema-pydantic 1.2.4\n",
      "packaging               24.1\n",
      "pandas                  2.2.2\n",
      "parso                   0.8.4\n",
      "pathos                  0.3.2\n",
      "pexpect                 4.9.0\n",
      "pickleshare             0.7.5\n",
      "pillow                  10.2.0\n",
      "pip                     24.0\n",
      "platformdirs            4.2.2\n",
      "pox                     0.3.4\n",
      "ppft                    1.7.6.8\n",
      "prompt_toolkit          3.0.47\n",
      "psutil                  6.0.0\n",
      "ptyprocess              0.7.0\n",
      "pure_eval               0.2.3\n",
      "pydantic                1.10.17\n",
      "Pygments                2.18.0\n",
      "PyJWT                   2.8.0\n",
      "python-dateutil         2.9.0\n",
      "python-dotenv           1.0.1\n",
      "pytz                    2024.1\n",
      "PyYAML                  6.0.1\n",
      "pyzmq                   25.1.2\n",
      "regex                   2024.7.24\n",
      "requests                2.32.3\n",
      "requests-file           2.1.0\n",
      "s3transfer              0.10.2\n",
      "setuptools              69.5.1\n",
      "sgmllib3k               1.0.0\n",
      "six                     1.16.0\n",
      "sniffio                 1.3.1\n",
      "soupsieve               2.5\n",
      "SQLAlchemy              2.0.31\n",
      "stack-data              0.6.2\n",
      "tenacity                8.5.0\n",
      "tiktoken                0.7.0\n",
      "tinysegmenter           0.3\n",
      "tldextract              5.1.2\n",
      "tornado                 6.4.1\n",
      "tqdm                    4.66.4\n",
      "traitlets               5.14.3\n",
      "typing_extensions       4.12.2\n",
      "typing-inspect          0.9.0\n",
      "tzdata                  2024.1\n",
      "urllib3                 2.2.2\n",
      "wcwidth                 0.2.13\n",
      "wheel                   0.43.0\n",
      "wikipedia               1.4.0\n",
      "wrapt                   1.16.0\n",
      "yarl                    1.9.4\n",
      "zipp                    3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNGFRtEzF+pmpVnazWF2eIb",
   "collapsed_sections": [
    "mtGKUVg3wI0d"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
