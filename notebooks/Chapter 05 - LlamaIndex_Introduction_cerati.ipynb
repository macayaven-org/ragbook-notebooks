{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2005%20-%20LlamaIndex_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to mode 2 to reload all modules automatically\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain openai python-dotenv pypdf deeplake langchain-community llama-index-vector-stores-deeplake\n",
    "%pip install -q requests beautifulsoup4 llama-index faiss-cpu openai llama-index-vector-stores-faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ['ACTIVELOOP_TOKEN']\n",
    "\n",
    "# Set the API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tjwZjA8-wITr"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "#You can set the logging level to DEBUG for more verbose output,\n",
    "# or use level=logging.INFO for less detailed information.\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLUDcXpI41Q_"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhaDzVaxwIRD",
    "outputId": "fc9cb5c0-c1b3-4641-c37c-77a93ff5eba9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48808/167685543.py:3: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "  WikipediaReader = download_loader(\"WikipediaReader\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-wikipedia in ./.conda/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.conda/lib/python3.10/site-packages (from llama-index-readers-wikipedia) (0.10.62)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.10.1)\n",
      "Requirement already satisfied: dataclasses-json in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.6.1)\n",
      "Requirement already satisfied: httpx in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.40.1)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.0.3)\n",
      "Requirement already satisfied: click in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.7.24)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.vector_stores import FaissVectorStore\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.indices.composability import ComposableGraph\n",
    "from llama_index.indices.keyword_table import KeywordTableIndex\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing data from cerati_lyrics_and_meanings.json\n",
      "Collected data for 169 songs.\n",
      "\n",
      "Sample data:\n",
      "Lyrics: Por aquello que encontré en tus ojosPor aquello que perdí en la luchaConocer la otra mitad es pocoCo...\n",
      "Meaning: La Búsqueda de la Plenitud en 'Vivo' de Gustavo CeratiLa canción 'Vivo' de Gustavo Cerati, una figur...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_song_urls(base_url: str) -> List[str]:\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    song_elements = soup.select('li.songList-table-row.--song')\n",
    "    \n",
    "    urls = []\n",
    "    for element in song_elements:\n",
    "        share_url = element.get('data-shareurl')\n",
    "        if share_url:\n",
    "            urls.append(share_url)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def get_lyrics_and_meaning(url: str) -> Tuple[str, str]:\n",
    "    # Get lyrics\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    lyrics = soup.select_one('div.lyric-original')\n",
    "    lyrics_text = lyrics.get_text(strip=True) if lyrics else \"\"\n",
    "    \n",
    "    # Get meaning\n",
    "    meaning_url = url.rstrip('/') + '/significado.html'\n",
    "    meaning_response = requests.get(meaning_url)\n",
    "    meaning_soup = BeautifulSoup(meaning_response.text, 'html.parser')\n",
    "    \n",
    "    meaning = meaning_soup.select_one('div.lyric-meaning')\n",
    "    meaning_text = meaning.get_text(strip=True) if meaning else \"\"\n",
    "    \n",
    "    return lyrics_text, meaning_text\n",
    "\n",
    "def scrape_cerati_lyrics() -> List[Tuple[str, str]]:\n",
    "    base_url = \"https://www.letras.com/gustavo-cerati/\"\n",
    "    song_urls = get_song_urls(base_url)\n",
    "    lyrics_and_meanings = []\n",
    "\n",
    "    for url in song_urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "        lyrics, meaning = get_lyrics_and_meaning(url)\n",
    "        if lyrics or meaning:\n",
    "            lyrics_and_meanings.append((lyrics, meaning))\n",
    "        time.sleep(1)  # Be nice to the server\n",
    "\n",
    "    return lyrics_and_meanings\n",
    "\n",
    "def load_or_scrape_cerati_data(file_path='cerati_lyrics_and_meanings.json'):\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading existing data from {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(\"Scraping Cerati lyrics and meanings...\")\n",
    "        cerati_data = scrape_cerati_lyrics()\n",
    "        print(f\"Scraped {len(cerati_data)} songs.\")\n",
    "        \n",
    "        # Save the data to a file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cerati_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Data saved to {file_path}\")\n",
    "        \n",
    "        return cerati_data\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    cerati_data = load_or_scrape_cerati_data()\n",
    "    print(f\"Collected data for {len(cerati_data)} songs.\")\n",
    "    \n",
    "    # Print a sample to verify\n",
    "    if cerati_data:\n",
    "        print(\"\\nSample data:\")\n",
    "        print(\"Lyrics:\", cerati_data[0][0][:100] + \"...\" if cerati_data[0][0] else \"No lyrics\")\n",
    "        print(\"Meaning:\", cerati_data[0][1][:100] + \"...\" if cerati_data[0][1] else \"No meaning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the shadows of a broken dream,  \n",
      "Donde el tiempo se detuvo sin querer,  \n",
      "Un eco de silencio en mi ser,  \n",
      "Un susurro de recuerdos que no se pueden ver.  \n",
      "\n",
      "En el laberinto de un cráneo abierto,  \n",
      "Donde se esconde el misterio incierto,  \n",
      "Se desvanecen los colores del ayer,  \n",
      "En la danza eterna de un amanecer.  \n",
      "\n",
      "El disco que no fue, la canción sin final,  \n",
      "Un suspiro perdido en la inmensidad,  \n",
      "La melodía que se desvaneció en el viento,  \n",
      "En el eco de un lamento sin aliento.  \n",
      "\n",
      "La historia del ictus que me llevó,  \n",
      "Un latido que se perdió en la oscuridad,  \n",
      "Un destello de luz en la penumbra,  \n",
      "En el abrazo eterno de la eternidad.  \n",
      "\n",
      "Dedicada a Cris, Topi, Morgui y Naho,  \n",
      "En el lienzo de la vida que se despliega,  \n",
      "En cada nota de este canto sincero,  \n",
      "En la melodía eterna que el corazón entrega.  \n",
      "\n",
      "Análisis: La canción habla de la experiencia de enfrentar la pérdida, la nostalgia y la esperanza a través de metáforas visuales y emocionales. Describe un viaje interno a través de la memoria y la superación de momentos difíciles, dedicado a seres queridos que han sido parte de ese camino. La letra refleja la dualidad de la melancolía y la luz que puede surgir de la oscuridad, transmitiendo un mensaje de amor y conexión a pesar de la adversidad.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.composability import ComposableGraph\n",
    "from llama_index.core.indices.keyword_table import KeywordTableIndex\n",
    "from llama_index.core.query_engine import MultiStepQueryEngine\n",
    "from llama_index.core.readers.download import download_loader\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Download and initialize the WikipediaReader\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "loader = WikipediaReader()\n",
    "\n",
    "# Fetch Gustavo Cerati's Wikipedia page\n",
    "cerati_wiki_documents = loader.load_data(pages=['Gustavo Cerati'])\n",
    "\n",
    "# Assuming cerati_data is available from the previous script\n",
    "lyrics_documents = []\n",
    "meaning_documents = []\n",
    "for lyrics, meaning in cerati_data:\n",
    "    lyrics_doc = Document(text=lyrics, metadata={\"type\": \"lyrics\"})\n",
    "    meaning_doc = Document(text=meaning, metadata={\"type\": \"meaning\"})\n",
    "    lyrics_documents.append(lyrics_doc)\n",
    "    meaning_documents.append(meaning_doc)\n",
    "\n",
    "# Set up models\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Update global settings\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "# Create FAISS index\n",
    "d = 1536  # dimensionality of text-embedding-3-small\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Create VectorStoreIndex for lyrics\n",
    "lyrics_index = VectorStoreIndex.from_documents(\n",
    "    lyrics_documents,\n",
    "    storage_context=storage_context\n",
    ")\n",
    "\n",
    "# Create KeywordTableIndex for meanings\n",
    "meaning_index = KeywordTableIndex.from_documents(\n",
    "    meaning_documents,\n",
    ")\n",
    "\n",
    "# Create a composable graph\n",
    "graph = ComposableGraph.from_indices(\n",
    "    KeywordTableIndex,\n",
    "    [lyrics_index, meaning_index],\n",
    "    index_summaries=[\"Lyrics of Gustavo Cerati songs\", \"Meanings of Gustavo Cerati songs\"]\n",
    ")\n",
    "\n",
    "# Create a query engine\n",
    "query_engine = graph.as_query_engine()\n",
    "\n",
    "# Function to generate creative text\n",
    "def generate_creative_text(prompt):\n",
    "    response = query_engine.query(\n",
    "        f\"Using the style and themes of Gustavo Cerati's lyrics, and considering their meanings, \"\n",
    "        f\"create a new full length song lyrics in spanish inspired by the following prompt: {prompt}. \"\n",
    "        f\"The response should be in the style of song lyrics. It should include an analysis of its meaning at the end\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "creative_prompt = \"Cráneo abierto, el disco que no fue y la historia del ictus que me llevó. Dedicada a Cris, Topi, Morgui y Naho\"\n",
    "new_text = generate_creative_text(creative_prompt)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing data from cerati_lyrics_and_meanings.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8491/2844707791.py:53: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "  WikipediaReader = download_loader(\"WikipediaReader\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-wikipedia in ./.conda/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.conda/lib/python3.10/site-packages (from llama-index-readers-wikipedia) (0.10.62)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.10.1)\n",
      "Requirement already satisfied: dataclasses-json in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.6.1)\n",
      "Requirement already satisfied: httpx in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.40.1)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.0.3)\n",
      "Requirement already satisfied: click in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.7.24)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n",
      "Number of lyrics documents: 169\n",
      "Number of meaning documents: 169\n",
      "Number of Wikipedia documents: 2\n",
      "**Cráneo Abierto**\n",
      "\n",
      "(Verse 1)  \n",
      "En la penumbra de un susurro,  \n",
      "las sombras juegan en mi piel,  \n",
      "un cráneo abierto, un laberinto,  \n",
      "donde los ecos vuelven a nacer.  \n",
      "Las ideas fluyen como ríos,  \n",
      "en un torrente de luz y de fe,  \n",
      "cada pensamiento es un destello,  \n",
      "un reflejo de lo que no se ve.\n",
      "\n",
      "(Chorus)  \n",
      "Cráneo abierto, corazón sincero,  \n",
      "buscando respuestas en el silencio.  \n",
      "Las voces del alma, un canto eterno,  \n",
      "en este viaje, soy el viajero.  \n",
      "Cráneo abierto, sin miedo a caer,  \n",
      "las verdades ocultas empiezan a arder.  \n",
      "En la fragilidad de lo que soy,  \n",
      "encuentro la fuerza, me vuelvo a crear.\n",
      "\n",
      "(Verse 2)  \n",
      "Las cicatrices cuentan historias,  \n",
      "de amores perdidos y sueños de ayer,  \n",
      "cada herida es una memoria,  \n",
      "un mapa que guía mi amanecer.  \n",
      "En la tormenta de mis pensamientos,  \n",
      "las dudas flotan como un papel,  \n",
      "pero en el caos, hallo el momento,  \n",
      "donde el dolor se convierte en miel.\n",
      "\n",
      "(Chorus)  \n",
      "Cráneo abierto, corazón sincero,  \n",
      "buscando respuestas en el silencio.  \n",
      "Las voces del alma, un canto eterno,  \n",
      "en este viaje, soy el viajero.  \n",
      "Cráneo abierto, sin miedo a caer,  \n",
      "las verdades ocultas empiezan a arder.  \n",
      "En la fragilidad de lo que soy,  \n",
      "encuentro la fuerza, me vuelvo a crear.\n",
      "\n",
      "(Bridge)  \n",
      "Y si el abismo me llama,  \n",
      "si la luna me quiere atrapar,  \n",
      "en cada paso, en cada drama,  \n",
      "renazco en el fuego, vuelvo a brillar.  \n",
      "Cráneo abierto, un universo,  \n",
      "donde el amor y el miedo se encuentran,  \n",
      "en la locura de ser sincero,  \n",
      "la vida se siente, se reinventa.\n",
      "\n",
      "(Chorus)  \n",
      "Cráneo abierto, corazón sincero,  \n",
      "buscando respuestas en el silencio.  \n",
      "Las voces del alma, un canto eterno,  \n",
      "en este viaje, soy el viajero.  \n",
      "Cráneo abierto, sin miedo a caer,  \n",
      "las verdades ocultas empiezan a arder.  \n",
      "En la fragilidad de lo que soy,  \n",
      "encuentro la fuerza, me vuelvo a crear.\n",
      "\n",
      "(Outro)  \n",
      "Cráneo abierto, un nuevo amanecer,  \n",
      "las luces del alma empiezan a ver.  \n",
      "En cada latido, en cada suspiro,  \n",
      "la vida se escribe, yo soy el giro.\n",
      "\n",
      "---\n",
      "\n",
      "**Análisis del significado:**  \n",
      "La letra de \"Cráneo Abierto\" explora la introspección y la búsqueda de significado en medio del caos emocional. El \"cráneo abierto\" simboliza una mente expuesta, donde las ideas y los sentimientos fluyen libremente, reflejando la vulnerabilidad y la autenticidad del ser. A través de imágenes de cicatrices y memorias, se aborda el dolor como parte del proceso de sanación y autodescubrimiento. La repetición del estribillo enfatiza la resiliencia y la capacidad de renacer a partir de las experiencias vividas, sugiriendo que en la fragilidad se encuentra la verdadera fuerza. La canción invita a abrazar la locura de ser uno mismo y a encontrar belleza en la transformación personal.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document, Settings, ServiceContext\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.keyword_table import KeywordTableIndex\n",
    "from llama_index.core.query_engine import MultiStepQueryEngine\n",
    "from llama_index.core.readers.download import download_loader\n",
    "\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors.pydantic_selectors import PydanticSingleSelector\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "def load_or_scrape_cerati_data(file_path='cerati_lyrics_and_meanings.json'):\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading existing data from {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        print(\"Scraping Cerati lyrics and meanings...\")\n",
    "        cerati_data = scrape_cerati_lyrics()\n",
    "        print(f\"Scraped {len(cerati_data)} songs.\")\n",
    "        \n",
    "        # Save the data to a file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cerati_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Data saved to {file_path}\")\n",
    "        \n",
    "        return cerati_data\n",
    "\n",
    "def create_documents(cerati_data):\n",
    "    lyrics_documents = []\n",
    "    meaning_documents = []\n",
    "    for lyrics, meaning in cerati_data:\n",
    "        lyrics_doc = Document(text=lyrics, metadata={\"type\": \"lyrics\"})\n",
    "        meaning_doc = Document(text=meaning, metadata={\"type\": \"meaning\"})\n",
    "        lyrics_documents.append(lyrics_doc)\n",
    "        meaning_documents.append(meaning_doc)\n",
    "    return lyrics_documents, meaning_documents\n",
    "\n",
    "# Load or scrape Cerati data\n",
    "cerati_data = load_or_scrape_cerati_data()\n",
    "\n",
    "# Create documents\n",
    "lyrics_documents, meaning_documents = create_documents(cerati_data)\n",
    "\n",
    "# Download and initialize the WikipediaReader\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "loader = WikipediaReader()\n",
    "cerati_wiki_documents = loader.load_data(pages=['Gustavo Cerati', 'Soda Stereo'])\n",
    "\n",
    "print(f\"Number of lyrics documents: {len(lyrics_documents)}\")\n",
    "print(f\"Number of meaning documents: {len(meaning_documents)}\")\n",
    "print(f\"Number of Wikipedia documents: {len(cerati_wiki_documents)}\")\n",
    "\n",
    "# Set up models with the specified versions\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Update global settings\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "\n",
    "# Create SimpleVectorStore\n",
    "vector_store = SimpleVectorStore()\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Create VectorStoreIndex for lyrics and Wikipedia biography\n",
    "lyrics_bio_index = VectorStoreIndex.from_documents(\n",
    "    lyrics_documents + cerati_wiki_documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    ")\n",
    "\n",
    "# Create KeywordTableIndex for meanings\n",
    "meaning_index = KeywordTableIndex.from_documents(\n",
    "    meaning_documents,\n",
    "    service_context=service_context,\n",
    ")\n",
    "\n",
    "# Create query engine tools\n",
    "lyrics_bio_tool = QueryEngineTool(\n",
    "    query_engine=lyrics_bio_index.as_query_engine(similarity_top_k=20),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"lyrics_and_bio\",\n",
    "        description=\"Useful for questions about Gustavo Cerati's lyrics and biography\"\n",
    "    )\n",
    ")\n",
    "\n",
    "meaning_tool = QueryEngineTool(\n",
    "    query_engine=meaning_index.as_query_engine(similarity_top_k=20),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"song_meanings\",\n",
    "        description=\"Useful for questions about the meanings of Gustavo Cerati's songs\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a router query engine\n",
    "router_query_engine = RouterQueryEngine(\n",
    "    selector=PydanticSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[lyrics_bio_tool, meaning_tool]\n",
    ")\n",
    "\n",
    "# Function to generate autobiographical creative text\n",
    "def generate_autobiographical_text(prompt):\n",
    "    response = router_query_engine.query(\n",
    "        f\"Using the style and themes of Gustavo Cerati's lyrics, and considering their meanings, \"\n",
    "        f\"create a new full length song lyrics in spanish inspired by the following prompt: {prompt}. \"\n",
    "        f\"The response should be in the style of song lyrics. It should include an analysis of its meaning at the end\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "creative_prompt = \"Cráneo abierto\"\n",
    "new_text = generate_autobiographical_text(creative_prompt)\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNGFRtEzF+pmpVnazWF2eIb",
   "collapsed_sections": [
    "mtGKUVg3wI0d"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
