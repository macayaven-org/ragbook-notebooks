{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2007%20-%20Create_a_YouTube_Video_Summarizer_Using_Whisper_and_LangChain_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OmcaMXwHaC",
        "outputId": "5d2a8e3e-916f-4aba-c1a4-8925dbb2de12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deeplake (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 deeplake openai==0.27.8 python-dotenv yt_dlp\n",
        "!pip install -q git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_kC-rOaw9_t",
        "outputId": "d5f34a0a-30dc-4033-fe0f-1cd75d2632b2"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv(dotenv_path='../.env')\n",
        "\n",
        "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')\n",
        "ACTIVELOOP_TOKEN=os.getenv('ACTIVELOOP_TOKEN')\n",
        "HF_API_KEY=os.getenv('HF_API_KEY')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-ffmpeg in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.0.12)\n",
            "Requirement already satisfied: pyee in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-ffmpeg) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-ffmpeg) (4.12.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libass9 libasyncns0 libavc1394-0 libavdevice58 libavfilter7 libavresample4\n",
            "  libbs2b0 libcaca0 libcdio-cdda2 libcdio-paranoia2 libcdio18 libdc1394-22\n",
            "  libfftw3-double3 libflac8 libflite1 libiec61883-0 libjack-jackd2-0\n",
            "  liblilv-0-0 libmysofa1 libnorm1 libopenal-data libopenal1 libpgm-5.2-0\n",
            "  libpostproc55 libpulse0 libraw1394-11 librubberband2 libsamplerate0\n",
            "  libsdl2-2.0-0 libserd-0-0 libslang2 libsndfile1 libsndio7.0 libsodium23\n",
            "  libsord-0-0 libsratom-0-0 libusb-1.0-0 libvidstab1.1 libwayland-cursor0\n",
            "  libwayland-egl1 libxss1 libxv1 libzmq5\n",
            "Suggested packages:\n",
            "  ffmpeg-doc libfftw3-bin libfftw3-dev jackd2 libportaudio2 pulseaudio\n",
            "  libraw1394-doc serdi sndiod sordi\n",
            "The following NEW packages will be installed:\n",
            "  ffmpeg libass9 libasyncns0 libavc1394-0 libavdevice58 libavfilter7\n",
            "  libavresample4 libbs2b0 libcaca0 libcdio-cdda2 libcdio-paranoia2 libcdio18\n",
            "  libdc1394-22 libfftw3-double3 libflac8 libflite1 libiec61883-0\n",
            "  libjack-jackd2-0 liblilv-0-0 libmysofa1 libnorm1 libopenal-data libopenal1\n",
            "  libpgm-5.2-0 libpostproc55 libpulse0 libraw1394-11 librubberband2\n",
            "  libsamplerate0 libsdl2-2.0-0 libserd-0-0 libslang2 libsndfile1 libsndio7.0\n",
            "  libsodium23 libsord-0-0 libsratom-0-0 libusb-1.0-0 libvidstab1.1\n",
            "  libwayland-cursor0 libwayland-egl1 libxss1 libxv1 libzmq5\n",
            "0 upgraded, 44 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 21.3 MB of archives.\n",
            "After this operation, 51.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libslang2 amd64 2.3.2-4 [429 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libsodium23 amd64 1.0.18-1 [150 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libusb-1.0-0 amd64 2:1.0.23-2build1 [46.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libraw1394-11 amd64 2.1.2-1 [30.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libavc1394-0 amd64 0.5.4-5 [16.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libass9 amd64 1:0.14.0-2 [88.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbs2b0 amd64 3.1.0+dfsg-2.2build1 [10.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 libflite1 amd64 2.1-release-3 [12.8 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 libserd-0-0 amd64 0.30.2-1 [46.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsord-0-0 amd64 0.16.4-1 [19.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsratom-0-0 amd64 0.6.4-1 [16.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 liblilv-0-0 amd64 0.24.6-1ubuntu0.1 [40.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/universe amd64 libmysofa1 amd64 1.0~dfsg0-1 [39.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpostproc55 amd64 7:4.2.7-0ubuntu0.1 [55.0 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu1 [728 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 libsamplerate0 amd64 0.1.9-2 [939 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal/universe amd64 librubberband2 amd64 1.8.2-1build1 [89.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal/universe amd64 libvidstab1.1 amd64 1.1.0-2 [35.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal/universe amd64 libnorm1 amd64 1.5.8+dfsg2-2build1 [290 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpgm-5.2-0 amd64 5.2.122~dfsg-3ubuntu1 [158 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzmq5 amd64 4.3.2-2ubuntu1 [242 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavfilter7 amd64 7:4.2.7-0ubuntu0.1 [1085 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcaca0 amd64 0.99.beta19-2.1ubuntu1.20.04.2 [203 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcdio18 amd64 2.0.0-2ubuntu0.2 [59.4 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio-cdda2 amd64 10.2+2.0.0-1 [17.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio-paranoia2 amd64 10.2+2.0.0-1 [16.2 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu focal/universe amd64 libdc1394-22 amd64 2.2.5-2.1 [79.6 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu focal/main amd64 libiec61883-0 amd64 1.2.0-3 [24.3 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu focal/main amd64 libjack-jackd2-0 amd64 1.9.12~dfsg-2ubuntu2 [267 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenal-data all 1:1.19.1-1 [162 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsndio7.0 amd64 1.5.0-3 [24.5 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenal1 amd64 1:1.19.1-1 [492 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu focal/main amd64 libasyncns0 amd64 0.8-6 [12.1 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libflac8 amd64 1.3.3-1ubuntu0.2 [103 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsndfile1 amd64 1.0.28-7ubuntu0.2 [170 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpulse0 amd64 1:13.99.1-1ubuntu3.13 [262 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-cursor0 amd64 1.18.0-1ubuntu0.1 [10.3 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-egl1 amd64 1.18.0-1ubuntu0.1 [5596 B]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu focal/main amd64 libxss1 amd64 1:1.2.3-1 [8140 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsdl2-2.0-0 amd64 2.0.10+dfsg1-3 [407 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu focal/main amd64 libxv1 amd64 2:1.0.11-1 [10.7 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavdevice58 amd64 7:4.2.7-0ubuntu0.1 [74.3 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavresample4 amd64 7:4.2.7-0ubuntu0.1 [54.2 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 ffmpeg amd64 7:4.2.7-0ubuntu0.1 [1453 kB]\n",
            "Fetched 21.3 MB in 2s (12.6 MB/s)\n",
            "debconf: delaying package configuration, since apt-utils is not installed\n",
            "Selecting previously unselected package libslang2:amd64.\n",
            "(Reading database ... 59170 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libslang2_2.3.2-4_amd64.deb ...\n",
            "Unpacking libslang2:amd64 (2.3.2-4) ...\n",
            "Selecting previously unselected package libsodium23:amd64.\n",
            "Preparing to unpack .../01-libsodium23_1.0.18-1_amd64.deb ...\n",
            "Unpacking libsodium23:amd64 (1.0.18-1) ...\n",
            "Selecting previously unselected package libusb-1.0-0:amd64.\n",
            "Preparing to unpack .../02-libusb-1.0-0_2%3a1.0.23-2build1_amd64.deb ...\n",
            "Unpacking libusb-1.0-0:amd64 (2:1.0.23-2build1) ...\n",
            "Selecting previously unselected package libraw1394-11:amd64.\n",
            "Preparing to unpack .../03-libraw1394-11_2.1.2-1_amd64.deb ...\n",
            "Unpacking libraw1394-11:amd64 (2.1.2-1) ...\n",
            "Selecting previously unselected package libavc1394-0:amd64.\n",
            "Preparing to unpack .../04-libavc1394-0_0.5.4-5_amd64.deb ...\n",
            "Unpacking libavc1394-0:amd64 (0.5.4-5) ...\n",
            "Selecting previously unselected package libass9:amd64.\n",
            "Preparing to unpack .../05-libass9_1%3a0.14.0-2_amd64.deb ...\n",
            "Unpacking libass9:amd64 (1:0.14.0-2) ...\n",
            "Selecting previously unselected package libbs2b0:amd64.\n",
            "Preparing to unpack .../06-libbs2b0_3.1.0+dfsg-2.2build1_amd64.deb ...\n",
            "Unpacking libbs2b0:amd64 (3.1.0+dfsg-2.2build1) ...\n",
            "Selecting previously unselected package libflite1:amd64.\n",
            "Preparing to unpack .../07-libflite1_2.1-release-3_amd64.deb ...\n",
            "Unpacking libflite1:amd64 (2.1-release-3) ...\n",
            "Selecting previously unselected package libserd-0-0:amd64.\n",
            "Preparing to unpack .../08-libserd-0-0_0.30.2-1_amd64.deb ...\n",
            "Unpacking libserd-0-0:amd64 (0.30.2-1) ...\n",
            "Selecting previously unselected package libsord-0-0:amd64.\n",
            "Preparing to unpack .../09-libsord-0-0_0.16.4-1_amd64.deb ...\n",
            "Unpacking libsord-0-0:amd64 (0.16.4-1) ...\n",
            "Selecting previously unselected package libsratom-0-0:amd64.\n",
            "Preparing to unpack .../10-libsratom-0-0_0.6.4-1_amd64.deb ...\n",
            "Unpacking libsratom-0-0:amd64 (0.6.4-1) ...\n",
            "Selecting previously unselected package liblilv-0-0:amd64.\n",
            "Preparing to unpack .../11-liblilv-0-0_0.24.6-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblilv-0-0:amd64 (0.24.6-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libmysofa1:amd64.\n",
            "Preparing to unpack .../12-libmysofa1_1.0~dfsg0-1_amd64.deb ...\n",
            "Unpacking libmysofa1:amd64 (1.0~dfsg0-1) ...\n",
            "Selecting previously unselected package libpostproc55:amd64.\n",
            "Preparing to unpack .../13-libpostproc55_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpostproc55:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../14-libfftw3-double3_3.3.8-2ubuntu1_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu1) ...\n",
            "Selecting previously unselected package libsamplerate0:amd64.\n",
            "Preparing to unpack .../15-libsamplerate0_0.1.9-2_amd64.deb ...\n",
            "Unpacking libsamplerate0:amd64 (0.1.9-2) ...\n",
            "Selecting previously unselected package librubberband2:amd64.\n",
            "Preparing to unpack .../16-librubberband2_1.8.2-1build1_amd64.deb ...\n",
            "Unpacking librubberband2:amd64 (1.8.2-1build1) ...\n",
            "Selecting previously unselected package libvidstab1.1:amd64.\n",
            "Preparing to unpack .../17-libvidstab1.1_1.1.0-2_amd64.deb ...\n",
            "Unpacking libvidstab1.1:amd64 (1.1.0-2) ...\n",
            "Selecting previously unselected package libnorm1:amd64.\n",
            "Preparing to unpack .../18-libnorm1_1.5.8+dfsg2-2build1_amd64.deb ...\n",
            "Unpacking libnorm1:amd64 (1.5.8+dfsg2-2build1) ...\n",
            "Selecting previously unselected package libpgm-5.2-0:amd64.\n",
            "Preparing to unpack .../19-libpgm-5.2-0_5.2.122~dfsg-3ubuntu1_amd64.deb ...\n",
            "Unpacking libpgm-5.2-0:amd64 (5.2.122~dfsg-3ubuntu1) ...\n",
            "Selecting previously unselected package libzmq5:amd64.\n",
            "Preparing to unpack .../20-libzmq5_4.3.2-2ubuntu1_amd64.deb ...\n",
            "Unpacking libzmq5:amd64 (4.3.2-2ubuntu1) ...\n",
            "Selecting previously unselected package libavfilter7:amd64.\n",
            "Preparing to unpack .../21-libavfilter7_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavfilter7:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Selecting previously unselected package libcaca0:amd64.\n",
            "Preparing to unpack .../22-libcaca0_0.99.beta19-2.1ubuntu1.20.04.2_amd64.deb ...\n",
            "Unpacking libcaca0:amd64 (0.99.beta19-2.1ubuntu1.20.04.2) ...\n",
            "Selecting previously unselected package libcdio18:amd64.\n",
            "Preparing to unpack .../23-libcdio18_2.0.0-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libcdio18:amd64 (2.0.0-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libcdio-cdda2:amd64.\n",
            "Preparing to unpack .../24-libcdio-cdda2_10.2+2.0.0-1_amd64.deb ...\n",
            "Unpacking libcdio-cdda2:amd64 (10.2+2.0.0-1) ...\n",
            "Selecting previously unselected package libcdio-paranoia2:amd64.\n",
            "Preparing to unpack .../25-libcdio-paranoia2_10.2+2.0.0-1_amd64.deb ...\n",
            "Unpacking libcdio-paranoia2:amd64 (10.2+2.0.0-1) ...\n",
            "Selecting previously unselected package libdc1394-22:amd64.\n",
            "Preparing to unpack .../26-libdc1394-22_2.2.5-2.1_amd64.deb ...\n",
            "Unpacking libdc1394-22:amd64 (2.2.5-2.1) ...\n",
            "Selecting previously unselected package libiec61883-0:amd64.\n",
            "Preparing to unpack .../27-libiec61883-0_1.2.0-3_amd64.deb ...\n",
            "Unpacking libiec61883-0:amd64 (1.2.0-3) ...\n",
            "Selecting previously unselected package libjack-jackd2-0:amd64.\n",
            "Preparing to unpack .../28-libjack-jackd2-0_1.9.12~dfsg-2ubuntu2_amd64.deb ...\n",
            "Unpacking libjack-jackd2-0:amd64 (1.9.12~dfsg-2ubuntu2) ...\n",
            "Selecting previously unselected package libopenal-data.\n",
            "Preparing to unpack .../29-libopenal-data_1%3a1.19.1-1_all.deb ...\n",
            "Unpacking libopenal-data (1:1.19.1-1) ...\n",
            "Selecting previously unselected package libsndio7.0:amd64.\n",
            "Preparing to unpack .../30-libsndio7.0_1.5.0-3_amd64.deb ...\n",
            "Unpacking libsndio7.0:amd64 (1.5.0-3) ...\n",
            "Selecting previously unselected package libopenal1:amd64.\n",
            "Preparing to unpack .../31-libopenal1_1%3a1.19.1-1_amd64.deb ...\n",
            "Unpacking libopenal1:amd64 (1:1.19.1-1) ...\n",
            "Selecting previously unselected package libasyncns0:amd64.\n",
            "Preparing to unpack .../32-libasyncns0_0.8-6_amd64.deb ...\n",
            "Unpacking libasyncns0:amd64 (0.8-6) ...\n",
            "Selecting previously unselected package libflac8:amd64.\n",
            "Preparing to unpack .../33-libflac8_1.3.3-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libflac8:amd64 (1.3.3-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libsndfile1:amd64.\n",
            "Preparing to unpack .../34-libsndfile1_1.0.28-7ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsndfile1:amd64 (1.0.28-7ubuntu0.2) ...\n",
            "Selecting previously unselected package libpulse0:amd64.\n",
            "Preparing to unpack .../35-libpulse0_1%3a13.99.1-1ubuntu3.13_amd64.deb ...\n",
            "Unpacking libpulse0:amd64 (1:13.99.1-1ubuntu3.13) ...\n",
            "Selecting previously unselected package libwayland-cursor0:amd64.\n",
            "Preparing to unpack .../36-libwayland-cursor0_1.18.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-cursor0:amd64 (1.18.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libwayland-egl1:amd64.\n",
            "Preparing to unpack .../37-libwayland-egl1_1.18.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-egl1:amd64 (1.18.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libxss1:amd64.\n",
            "Preparing to unpack .../38-libxss1_1%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxss1:amd64 (1:1.2.3-1) ...\n",
            "Selecting previously unselected package libsdl2-2.0-0:amd64.\n",
            "Preparing to unpack .../39-libsdl2-2.0-0_2.0.10+dfsg1-3_amd64.deb ...\n",
            "Unpacking libsdl2-2.0-0:amd64 (2.0.10+dfsg1-3) ...\n",
            "Selecting previously unselected package libxv1:amd64.\n",
            "Preparing to unpack .../40-libxv1_2%3a1.0.11-1_amd64.deb ...\n",
            "Unpacking libxv1:amd64 (2:1.0.11-1) ...\n",
            "Selecting previously unselected package libavdevice58:amd64.\n",
            "Preparing to unpack .../41-libavdevice58_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavdevice58:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Selecting previously unselected package libavresample4:amd64.\n",
            "Preparing to unpack .../42-libavresample4_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking libavresample4:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Selecting previously unselected package ffmpeg.\n",
            "Preparing to unpack .../43-ffmpeg_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\n",
            "Unpacking ffmpeg (7:4.2.7-0ubuntu0.1) ...\n",
            "Setting up libraw1394-11:amd64 (2.1.2-1) ...\n",
            "Setting up libsodium23:amd64 (1.0.18-1) ...\n",
            "Setting up libnorm1:amd64 (1.5.8+dfsg2-2build1) ...\n",
            "Setting up libmysofa1:amd64 (1.0~dfsg0-1) ...\n",
            "Setting up libcdio18:amd64 (2.0.0-2ubuntu0.2) ...\n",
            "Setting up libavresample4:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Setting up libflac8:amd64 (1.3.3-1ubuntu0.2) ...\n",
            "Setting up libass9:amd64 (1:0.14.0-2) ...\n",
            "Setting up libslang2:amd64 (2.3.2-4) ...\n",
            "Setting up libxv1:amd64 (2:1.0.11-1) ...\n",
            "Setting up libpostproc55:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu1) ...\n",
            "Setting up libsndio7.0:amd64 (1.5.0-3) ...\n",
            "Setting up libvidstab1.1:amd64 (1.1.0-2) ...\n",
            "Setting up libflite1:amd64 (2.1-release-3) ...\n",
            "Setting up libasyncns0:amd64 (0.8-6) ...\n",
            "Setting up libwayland-cursor0:amd64 (1.18.0-1ubuntu0.1) ...\n",
            "Setting up libbs2b0:amd64 (3.1.0+dfsg-2.2build1) ...\n",
            "Setting up libopenal-data (1:1.19.1-1) ...\n",
            "Setting up libwayland-egl1:amd64 (1.18.0-1ubuntu0.1) ...\n",
            "Setting up libxss1:amd64 (1:1.2.3-1) ...\n",
            "Setting up libusb-1.0-0:amd64 (2:1.0.23-2build1) ...\n",
            "Setting up libsndfile1:amd64 (1.0.28-7ubuntu0.2) ...\n",
            "Setting up libsamplerate0:amd64 (0.1.9-2) ...\n",
            "Setting up libpgm-5.2-0:amd64 (5.2.122~dfsg-3ubuntu1) ...\n",
            "Setting up libiec61883-0:amd64 (1.2.0-3) ...\n",
            "Setting up libserd-0-0:amd64 (0.30.2-1) ...\n",
            "Setting up libavc1394-0:amd64 (0.5.4-5) ...\n",
            "Setting up libzmq5:amd64 (4.3.2-2ubuntu1) ...\n",
            "Setting up libcaca0:amd64 (0.99.beta19-2.1ubuntu1.20.04.2) ...\n",
            "Setting up libpulse0:amd64 (1:13.99.1-1ubuntu3.13) ...\n",
            "Setting up libcdio-cdda2:amd64 (10.2+2.0.0-1) ...\n",
            "Setting up libcdio-paranoia2:amd64 (10.2+2.0.0-1) ...\n",
            "Setting up libdc1394-22:amd64 (2.2.5-2.1) ...\n",
            "Setting up libopenal1:amd64 (1:1.19.1-1) ...\n",
            "Setting up librubberband2:amd64 (1.8.2-1build1) ...\n",
            "Setting up libjack-jackd2-0:amd64 (1.9.12~dfsg-2ubuntu2) ...\n",
            "Setting up libsord-0-0:amd64 (0.16.4-1) ...\n",
            "Setting up libsratom-0-0:amd64 (0.6.4-1) ...\n",
            "Setting up libsdl2-2.0-0:amd64 (2.0.10+dfsg1-3) ...\n",
            "Setting up liblilv-0-0:amd64 (0.24.6-1ubuntu0.1) ...\n",
            "Setting up libavfilter7:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Setting up libavdevice58:amd64 (7:4.2.7-0ubuntu0.1) ...\n",
            "Setting up ffmpeg (7:4.2.7-0ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.16) ...\n"
          ]
        }
      ],
      "source": [
        "%pip install python-ffmpeg\n",
        "!sudo apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb9TdVmOxVVw",
        "outputId": "65b7925a-7e34-4439-9733-e561edfb2f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " que nos vamos a presentar. Bueno, Gustavo, estamos en Los Ángeles, estamos yendo al Nokia, que en una solita vamos a estar un poquito tocando ehh se da cuenta en cada ciudad a la que va que por ejemplo Los Ángeles que a que te remite humana y musicalmente me refiero. Y yo vengo a a Estados Unidos y a Los Ángeles particularmente desde el ochenta y siete ochenta y siete que fue la que el primer fue el primer show que hicimos con Soda Estéreo y y desde y ya bueno es un lugar en donde teóricamente todas las cosas a nivel técnico están bien, ¿no? Todo tan pulpo y perfecto. Me gusta también ver a veces que todo eso que funciona de golpe se desmorona, ¿no? Ehh pero si yo vivo lo más intensamente que puedo en los lugares o sea no soy de quedarme en el hotel, ¿viste? Es algo que esté muy arruinado necesito salir un poco, ¿viste? Y meterme en el hotel y no no me gusta ir a un poco, ¿viste? Y meterme ahí y eso no. Cambiaron un poquito las giras, me imagino que sí, ¿no? Uno va creciendo y también va teniendo otros humores. Recién hablaba de los ochenta cuando giraban, después de los noventa, ¿eh? Y ahora me imagino que las viví de otras maneras, ¿no? Mismo los músicos también, ¿no? Los ochenta eran de mal humor. Específicamente. No, pero digo, yo creo que ahora me parece que que raro porque uno de afuera los los veía tan sonrientes. Sí, no, bueno que pero también lo que que también estabas al mango de la noche, ¿no? No, no, no tenía ni consciencia de lo que pasaba y y era el espacio perfecto para para endivarse y protestar por Diego Ludez. De todas maneras lo disfruté. Pero yo creo que ahora realmente tiene que ver con la edad, tiene que ver con cómo uno ya las también porque con Soda hemos estado ponere seis meses sin volver a casa, entonces te naturalizas mucho, cuando llegamos a ver dónde está tu casa, ¿no? Como que medio raro todo eso que es algo bastante muy raro, no? Porque ya no hay bandas ehh inglesas, americanas, así internacional. Así terminan también, ¿no? Y es muy jodido ese ese asunto, ¿no? Llevás a toda la prole y toda tu toda tu tu casa con vos como una torre. Ya no es una gira de rock eso. Claro. O viste cuando volvés y dices hello, esto era todo. Ahora ya no, las giras son en general no duran más de un mes que es más o menos el tiempo en que me dura el mejor humor, ¿no? Porque para todos, digo, en general también es una gran oportunidad. Por suerte también mi banda y la gente que que me rodea son gente que conozco y muchos están en muchísimo tiempo así que nos conocemos muy bien casi sin hablarnos y tengo la sensación de que ahora eh disfruto más ehh realmente desde un tiempo esta parte ehh me me da me de por sí me me otorga un buen humor salir de gira y es algo que deseo que me gusta. Te lo esperas. Y te agradezco también porque viste en un momento no me da cuenta que estaba no estaba agradeciendo algo tan bueno como conocer lugares que de otra manera no sé el estado de la banda. Contame la banda, ¿cómo está después de tantos años? Recién decías con varios de ellos, hablabas de la parte humana, de de la amistad que tenés con muchos de ellos, desde lo musical me imagino que ya son Fórmula Uno, ¿no? Desde lo musical vengo al pedo. A decir, podría no, podría no venir. Podría no venir. Son tremendos. Me encanta lo que pasa. Son músicos. Todos. Yo yo admiro, por supuesto, pero además eso se ha formado por el tiempo y también por una cuestión de personalidades, una integración que es muy importante, ¿viste? Porque me siento más tranquilo que nunca con eso, como diciendo, ¿no? Yo si me retro traigo a la a la primera época cuando, digamos, se había suelto a este, entonces, bueno, soy solista, ¿qué voy a hacer? Vivo contratar músicos, ¿no? Como uno piensa un solista con música contratada, nunca termina de haber una verdadera afinidad. Por suerte quizás y por el legado de haber sido parte de una banda, me he conformado un grupo de gente o he tenido la suerte o lo que como se llame de que de que sean más que eso, ¿no? Más que. Si no no se podría hacer todo esto, ¿no? Tampoco. Como latina. Costaría más. Pero los sean que son tan los ingleses están acostumbrados a esto. Se ven arriba del escenario. Carista que toca con viste con David y Rod y después tocan así, ¿no? Sí, músico de sesión. Claro, trabajo. Lo cual también igual no quiere decir que eso no tenga sensibilidad, músicos grozos, eso, pero todos los, por ejemplo, Martin Phillips que es el que organizó toda la parte visual del grupo que es en inglés, de de lo que estamos haciendo de los shows, me cuenta, ¿no? Me dice el tipo cuando cuando se da cuenta del clima que vivimos entre nosotros, o sea, ingresa en ese lugar, no quiere salir más. Viste, me dice Kenny West, me caga, no quiero, ¿entendés? Está laburando con gente muy grossa, pero me llama por eso, como diciendo, lo sé, extraño. Y es un inglés que para que te diga te extraño, sabes lo que tenemos que tener. Esas cosas son importantes, están más importantes que la habilidad musical. Con tanta trayectoria, con tantas canciones, tantos discos, no se te conoce un bajón en tus no sé cuántas décadas de de la historia musical, no se te conoce, realmente uno decía, bueno, ahí vamos, llegó hasta hasta lo máximo que podía llegar, uno de los mejores discos de la historia del rock argentino, viene fuerza natural, lo mismo yendo para atrás, es como que te resulta fácil hacer buenos discos. No. Esa es la sensación que nos da. Es la sensación que da, sí, sí, pero no, no, al contrario, yo creo que tengo un nivel de autocrítica importante en lo que a mí respecta, por supuesto que no tengo ni ahí la la varita de saber realmente qué es lo que va a funcionar. Hay hay discos míos que han sido que no han sido, que no han tenido grandes ventas y eso, pero siempre. No por malos. Pero siempre claro, siempre, no, lo que pasa es que yo, para mí, digamos, no es como antes que a lo mejor significaban tanto mi vida, yo pienso que bueno, hay muchas otras cosas importantes, pero sí pienso que si suelto algo es algo de lo que tengo que estar orgulloso. Y por ahí, el hecho de que yo sea así un poco cambiante y tratando de buscar cosas nuevas, dime diferencia a lo mejor un poco de otras situaciones que ocurren y tal vez ese nivel de autocrítica también tiene su lado, porque a lo mejor yo no permito que muchas cosas supuestamente más espontáneas salgan, pero la verdad es que no encontré ninguna llave y sigo siendo como una especie de guerrero muy trabajador. No sos consciente de eso. Vos mirás para atrás. Sí, sí, sí, porque si pensás o de estéreo mismo, es un grupo que no ha tenido prácticamente, digamos, casi no ha tenido sombra, digo, así siempre un grupo que, no, su disco uno más que otra habrá vendido que yo, pero siempre estuvieron ta, ta, ta, ta. Y después solista te costó poco tiempo instalarte porque era muy difícil después de eso de estéreo. ¿Era desaparecer o esto que te pasó? Hay dos cosas que me parece que son esenciales. Por un lado es la el asunto de proponer algo diferente y animarse una especie de riesgo. Estoy dentro de la fea de la música pop y del rock, con poco es que estamos hablando de una vanguardia posible, digamos, de Vingery. Entonces, ¿qué es eso? No es que sea imposible, digamos, de Vingery. Entonces, ni, ni, ni, ni, ni, ni me estoy mandando la parte como, como artista ni mucho menos. Pues sí, creo que eso, sumado a la insistencia, ¿no? Como insistir en lo que realmente, en lo que uno cree, eso. Después el resultado, por eso te digo, el resultado termina siendo justicia. Es decir, puede que no venda tanto disco, puede que no sea tan exitoso, puede que no me gane tanto Grammy, todo lo que quieras. Pero lo que no es que me salió un disco, qué sé yo, porque así no más, ¿no es? Porque realmente ahí estoy trabajando. Bueno, si viene magia con single, con un remix, creo que de rapto y de magia, ¿no? Y un video también que en algunas semanas ya lo vamos a ver. Sí, filmamos un video un día antes de viajar para acá, para Lima, en realidad, que fue la primera parada. Y Leandro Fresco se está encargando de así de ser como el remixador, digamos, exclusivo. ¿Te metes ahí, urgaso o de casqueaga? No, no, le hice el mastering, por supuesto, de mis apreciaciones, Leandro me lo va mostrando en proceso de formación, pero es, es, es en gran parte del trabajo de él. Y pero también abro un poco el juego, creo que voy a hacer, tengo ganas de que, a lo mejor poner unas pistas por ahí, que la gente pueda remejar, como lo hice anteriormente con Siempre Soy. Y el video de magia que nos puedes contar, si lo vemos y mientras te involucraste mucho en el en el armado, en la idea. El video de magia es otro otro capítulo en una especie de historia que que se va escribiendo y que tiene diferentes momentos en el tiempo. Magia en el disco va antes de Desastre. RAPTO, que es el tema que ya hicimos, que lanzamos una discusión y con el video está después de Desastre. O sea que la historia de magia debería ser lo que ocurre entre Dejavu y Desastre, que todavía no te has filmado. Entonces, es como que un poco lo vamos. Hay que sentárnoslo, insertándolo. Exactamente. Así que, bueno, no se va a entender nada. Lo vamos a entender al final. Supuestamente. ¿Qué pensás de esta unión, no? De lo que se denomina latino, con lo que se denomina rock. Si hay diferencias, Fito tuvo un gran encontronazo con Arjona, pero al mismo tiempo, bueno, vos tenés una gran relación musical con Shakira, Calamaro grabó con Juanes, Vicentico con Ricky Martin, digo. ¿Es bien de argentino hacer esta pregunta, inclusive? ¿Es de argentino? Bueno, claro, es un tema, ¿no? Somos argentinos y tenemos que sortear una cantidad de cosas que tenemos muy impresas en el cerebro, empezando porque somos un país de rock. Donde el rock ha sido muy, estuvo muy presente en, no sé, mi adolescencia, y yo. Entonces, mismo dentro de Argentina está el prejuicio de que sos rock o no sos rock, ¿viste? Sí, sí. Es decir, algo que ya es como medio ridículo. Por suerte caduco, me parece. No sé, pero es ridículo, ¿qué sé yo? Pero también de alguna manera es herencia de aquella época en donde no decíamos música complaciente, música no complaciente, música progresiva. Comercial. Sí, Boca, River, Redondito, Soda. Iniesta García. Exacto. Entonces, como que esa cosa que tenemos así, este, la llevaremos por siempre jamás, pero bueno, no importa, digo, es un país tan musical argentina y somos muy admirados en ese aspecto por todos los otros artistas latinos que yo cono, por lo menos que he visto, ¿no? De hecho, Juanes ha venido a mi casa una vez, he sido muy fan, ¿viste? Shakira también cuando se acercó. Y si bien son otro palo, y uno podría decir, ¿no? Este, no sé yo, hacen una música que a lo mejor no es la que uno haría o la que uno consumiría, este, a veces está bueno cruzar esas experiencias. Yo he aprendido mucho con Shakira, a pesar de que ella vino a buscarme para, para que la ayudara con, con lo suyo, terminó ayudándome mucho y, y no desde el lugar de la exposición, porque eso digamos, es relativo, ¿sí? Me ha conocido mucha gente, que sé yo, a través de eso, pero no es quizás lo más importante, pero sí, por ejemplo, cómo se mueve una persona que tiene ese nivel de, de exigencia. Shakira es una persona que creo que debe ser la latina más conocida en todo el mundo. Se la pasa a la India, ¿viste? Es así. Entonces, yo creo que, que en la medida que uno es menos prejuicioso, mejor le va también en la vida y mejor puede ir también como artista moviéndose, porque qué sé, porque qué sé yo. Así que yo, yo lo, una de las cosas que yo citaría como muy interesante desde la Argentina, me parece que es algo que a tener muy, muy en cuenta es que cuando hubo, cuando ocurrió lo del terremoto de Chile, que, que se organizó ese, ese festival de ayuda y de abrazo a Chile, que se organizó en tres días, que lo hizo Juan Carr con la ayuda de todas, de nuestra, que yo, pero creo, lo hizo increíblemente, la gente, bebe, la gente era, era como si fueran chilenos, eran argentinos, eso no se veía antes. Totalmente. O sea, como que todos empezamos a entender que estamos en el mismo barco, ¿viste? Y el agua se está moviendo y es una agua del cual también nosotros somos responsables. Entonces, esa sensación de, de hermandad, digamos, alguna vez también, que no, que nosotros como argentinos siempre nos cuesta tragar. Absolutamente. Ver esa demostración de parte de la gente, para mí fue una de las cosas más lindas que yo he vivido en los últimos tiempos y me habló mucho también de Argentina. Gracias, ha gustado buen show, eh. No, no, a vos. No, no, no, no.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import ffmpeg\n",
        "API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-base\"\n",
        "headers = {\"Authorization\": f\"Bearer {HF_API_KEY}\"}\n",
        "\n",
        "model = whisper.load_model(\"medium\", device='cuda')\n",
        "result = model.transcribe(\"./cerati_interview.mp4\", language='es')\n",
        "print(result['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Ron Burgundy Podcast. Yes, let's talk about it. This is a very, very exciting. You have your own podcast. You call it exciting. I got Shanghai. What are you talking about? I didn't know what a podcast was. I thought it was my own talk show on television. Turns out I'm thrown into, you know, a padded room with a sweaty microphone. Wait, when you agreed to do a podcast, you didn't know what it was? It was too much money to say no. You've done some important work too. Is this true? I'm told by my people that you cracked the Zodiac Killer case on your podcast. We did. True crimes and mysteries. They're very popular. Very popular on podcast. So we cracked the Zodiac Killer. You did. That's a murder mystery that's... Been going on. And it's been... They haven't solved. It's been unsolved for... Oh, God. I don't know how. 35, 40 years. At least. Yeah. I've been deemed to know a little more about it than you do. Look, it sounds... You should come and do my podcast for me. Yeah. But yeah, we revealed to the audience that it was Ted Cruz. And it's exciting to, you know, break information like that. Out to people. Did you have a good evidence that it was... Really good evidence. Like, you want to get specific? It's hop-notch evidence. Like evidence that anyone in police work would go like, What? This is good evidence, man. Well, okay. Where'd you get this? Yeah. Were you invited to evidence shop? Yeah. What's going on here? Yeah. This evidence is so good, it seems fishy. Yeah. But, um, no, we got him. Ted. So, anyway, Ted, if you're watching, watch out. We know you... You've named him as the killer, but he's still free and no... As far as I know, I don't know what... I don't know what he does right now, but... Okay. All right. Let's just store for season two of the podcast. I mean, you set us pretty high bar for season one with your solving cases like that. What do you got? Solving cases. Season one, we were stuck in an elevator for one podcast. We did one for my haunted garage. What else? We interviewed RuPaul. Yeah. So we pretty much climbed the mountain. Yeah. Season two will be a bit of a letdown. Yeah. That's how he's... We're not really drawing that hard. Yeah. And some of them are just 45 minutes of dead air. Yeah. I'm going to give you a little advice. When you're promoting something, you want to make it sound, you want to build it up. Well, but I've never lied to my viewers. So, I'd like to build it up. Look. You can't make chicken salad out of chicken shit. I've always said it. Well, you heard it from the man himself. So, you make a good case. You got to listen to... Season two. Not that good. Season two. Season two of the Ron Burgundy podcast has been able to date wherever. Wherever you listen to my wife. Yeah, wherever. If you find out, tell me. Ron Burgundy.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-base\"\n",
        "headers = {\"Authorization\": f\"Bearer {HF_API_KEY}\"}\n",
        "\n",
        "model = whisper.load_model(\"base\", device='cuda')\n",
        "result2 = model.transcribe(\"./ron_burgundy_zodiac.mp4\", language='en')\n",
        "print(result2['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-N7NHMQJ4ZxE"
      },
      "outputs": [],
      "source": [
        "with open ('text.txt', 'w') as file:\n",
        "    file.write(result['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open ('text2.txt', 'w') as file:\n",
        "    file.write(result2['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C0WDaLA84aM6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_community/llms/openai.py:254: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_community/llms/openai.py:1075: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain import OpenAI, LLMChain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-40-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yt1b9kM566Su"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CNbgfAfR67GH"
      },
      "outputs": [],
      "source": [
        "with open('text.txt') as f:\n",
        "    text = f.read()\n",
        "texts = text_splitter.split_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "k5z5OQFS68or"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "docs = [Document(page_content=t) for t in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='que nos vamos a presentar. Bueno, Gustavo, estamos en Los Ángeles, estamos yendo al Nokia, que en una solita vamos a estar un poquito tocando ehh se da cuenta en cada ciudad a la que va que por ejemplo Los Ángeles que a que te remite humana y musicalmente me refiero. Y yo vengo a a Estados Unidos y a Los Ángeles particularmente desde el ochenta y siete ochenta y siete que fue la que el primer fue el primer show que hicimos con Soda Estéreo y y desde y ya bueno es un lugar en donde teóricamente todas las cosas a nivel técnico están bien, ¿no? Todo tan pulpo y perfecto. Me gusta también ver a veces que todo eso que funciona de golpe se desmorona, ¿no? Ehh pero si yo vivo lo más intensamente que puedo en los lugares o sea no soy de quedarme en el hotel, ¿viste? Es algo que esté muy arruinado necesito salir un poco, ¿viste? Y meterme en el hotel y no no me gusta ir a un poco, ¿viste? Y meterme ahí y eso no. Cambiaron un poquito las giras, me imagino que sí, ¿no? Uno va creciendo y también'),\n",
              " Document(page_content='va teniendo otros humores. Recién hablaba de los ochenta cuando giraban, después de los noventa, ¿eh? Y ahora me imagino que las viví de otras maneras, ¿no? Mismo los músicos también, ¿no? Los ochenta eran de mal humor. Específicamente. No, pero digo, yo creo que ahora me parece que que raro porque uno de afuera los los veía tan sonrientes. Sí, no, bueno que pero también lo que que también estabas al mango de la noche, ¿no? No, no, no tenía ni consciencia de lo que pasaba y y era el espacio perfecto para para endivarse y protestar por Diego Ludez. De todas maneras lo disfruté. Pero yo creo que ahora realmente tiene que ver con la edad, tiene que ver con cómo uno ya las también porque con Soda hemos estado ponere seis meses sin volver a casa, entonces te naturalizas mucho, cuando llegamos a ver dónde está tu casa, ¿no? Como que medio raro todo eso que es algo bastante muy raro, no? Porque ya no hay bandas ehh inglesas, americanas, así internacional. Así terminan también, ¿no? Y es muy'),\n",
              " Document(page_content='jodido ese ese asunto, ¿no? Llevás a toda la prole y toda tu toda tu tu casa con vos como una torre. Ya no es una gira de rock eso. Claro. O viste cuando volvés y dices hello, esto era todo. Ahora ya no, las giras son en general no duran más de un mes que es más o menos el tiempo en que me dura el mejor humor, ¿no? Porque para todos, digo, en general también es una gran oportunidad. Por suerte también mi banda y la gente que que me rodea son gente que conozco y muchos están en muchísimo tiempo así que nos conocemos muy bien casi sin hablarnos y tengo la sensación de que ahora eh disfruto más ehh realmente desde un tiempo esta parte ehh me me da me de por sí me me otorga un buen humor salir de gira y es algo que deseo que me gusta. Te lo esperas. Y te agradezco también porque viste en un momento no me da cuenta que estaba no estaba agradeciendo algo tan bueno como conocer lugares que de otra manera no sé el estado de la banda. Contame la banda, ¿cómo está después de tantos años? Recién'),\n",
              " Document(page_content='decías con varios de ellos, hablabas de la parte humana, de de la amistad que tenés con muchos de ellos, desde lo musical me imagino que ya son Fórmula Uno, ¿no? Desde lo musical vengo al pedo. A decir, podría no, podría no venir. Podría no venir. Son tremendos. Me encanta lo que pasa. Son músicos. Todos. Yo yo admiro, por supuesto, pero además eso se ha formado por el tiempo y también por una cuestión de personalidades, una integración que es muy importante, ¿viste? Porque me siento más tranquilo que nunca con eso, como diciendo, ¿no? Yo si me retro traigo a la a la primera época cuando, digamos, se había suelto a este, entonces, bueno, soy solista, ¿qué voy a hacer? Vivo contratar músicos, ¿no? Como uno piensa un solista con música contratada, nunca termina de haber una verdadera afinidad. Por suerte quizás y por el legado de haber sido parte de una banda, me he conformado un grupo de gente o he tenido la suerte o lo que como se llame de que de que sean más que eso, ¿no? Más que. Si'),\n",
              " Document(page_content='no no se podría hacer todo esto, ¿no? Tampoco. Como latina. Costaría más. Pero los sean que son tan los ingleses están acostumbrados a esto. Se ven arriba del escenario. Carista que toca con viste con David y Rod y después tocan así, ¿no? Sí, músico de sesión. Claro, trabajo. Lo cual también igual no quiere decir que eso no tenga sensibilidad, músicos grozos, eso, pero todos los, por ejemplo, Martin Phillips que es el que organizó toda la parte visual del grupo que es en inglés, de de lo que estamos haciendo de los shows, me cuenta, ¿no? Me dice el tipo cuando cuando se da cuenta del clima que vivimos entre nosotros, o sea, ingresa en ese lugar, no quiere salir más. Viste, me dice Kenny West, me caga, no quiero, ¿entendés? Está laburando con gente muy grossa, pero me llama por eso, como diciendo, lo sé, extraño. Y es un inglés que para que te diga te extraño, sabes lo que tenemos que tener. Esas cosas son importantes, están más importantes que la habilidad musical. Con tanta'),\n",
              " Document(page_content='trayectoria, con tantas canciones, tantos discos, no se te conoce un bajón en tus no sé cuántas décadas de de la historia musical, no se te conoce, realmente uno decía, bueno, ahí vamos, llegó hasta hasta lo máximo que podía llegar, uno de los mejores discos de la historia del rock argentino, viene fuerza natural, lo mismo yendo para atrás, es como que te resulta fácil hacer buenos discos. No. Esa es la sensación que nos da. Es la sensación que da, sí, sí, pero no, no, al contrario, yo creo que tengo un nivel de autocrítica importante en lo que a mí respecta, por supuesto que no tengo ni ahí la la varita de saber realmente qué es lo que va a funcionar. Hay hay discos míos que han sido que no han sido, que no han tenido grandes ventas y eso, pero siempre. No por malos. Pero siempre claro, siempre, no, lo que pasa es que yo, para mí, digamos, no es como antes que a lo mejor significaban tanto mi vida, yo pienso que bueno, hay muchas otras cosas importantes, pero sí pienso que si suelto'),\n",
              " Document(page_content='algo es algo de lo que tengo que estar orgulloso. Y por ahí, el hecho de que yo sea así un poco cambiante y tratando de buscar cosas nuevas, dime diferencia a lo mejor un poco de otras situaciones que ocurren y tal vez ese nivel de autocrítica también tiene su lado, porque a lo mejor yo no permito que muchas cosas supuestamente más espontáneas salgan, pero la verdad es que no encontré ninguna llave y sigo siendo como una especie de guerrero muy trabajador. No sos consciente de eso. Vos mirás para atrás. Sí, sí, sí, porque si pensás o de estéreo mismo, es un grupo que no ha tenido prácticamente, digamos, casi no ha tenido sombra, digo, así siempre un grupo que, no, su disco uno más que otra habrá vendido que yo, pero siempre estuvieron ta, ta, ta, ta. Y después solista te costó poco tiempo instalarte porque era muy difícil después de eso de estéreo. ¿Era desaparecer o esto que te pasó? Hay dos cosas que me parece que son esenciales. Por un lado es la el asunto de proponer algo'),\n",
              " Document(page_content='diferente y animarse una especie de riesgo. Estoy dentro de la fea de la música pop y del rock, con poco es que estamos hablando de una vanguardia posible, digamos, de Vingery. Entonces, ¿qué es eso? No es que sea imposible, digamos, de Vingery. Entonces, ni, ni, ni, ni, ni, ni me estoy mandando la parte como, como artista ni mucho menos. Pues sí, creo que eso, sumado a la insistencia, ¿no? Como insistir en lo que realmente, en lo que uno cree, eso. Después el resultado, por eso te digo, el resultado termina siendo justicia. Es decir, puede que no venda tanto disco, puede que no sea tan exitoso, puede que no me gane tanto Grammy, todo lo que quieras. Pero lo que no es que me salió un disco, qué sé yo, porque así no más, ¿no es? Porque realmente ahí estoy trabajando. Bueno, si viene magia con single, con un remix, creo que de rapto y de magia, ¿no? Y un video también que en algunas semanas ya lo vamos a ver. Sí, filmamos un video un día antes de viajar para acá, para Lima, en realidad,'),\n",
              " Document(page_content='que fue la primera parada. Y Leandro Fresco se está encargando de así de ser como el remixador, digamos, exclusivo. ¿Te metes ahí, urgaso o de casqueaga? No, no, le hice el mastering, por supuesto, de mis apreciaciones, Leandro me lo va mostrando en proceso de formación, pero es, es, es en gran parte del trabajo de él. Y pero también abro un poco el juego, creo que voy a hacer, tengo ganas de que, a lo mejor poner unas pistas por ahí, que la gente pueda remejar, como lo hice anteriormente con Siempre Soy. Y el video de magia que nos puedes contar, si lo vemos y mientras te involucraste mucho en el en el armado, en la idea. El video de magia es otro otro capítulo en una especie de historia que que se va escribiendo y que tiene diferentes momentos en el tiempo. Magia en el disco va antes de Desastre. RAPTO, que es el tema que ya hicimos, que lanzamos una discusión y con el video está después de Desastre. O sea que la historia de magia debería ser lo que ocurre entre Dejavu y Desastre,'),\n",
              " Document(page_content='que todavía no te has filmado. Entonces, es como que un poco lo vamos. Hay que sentárnoslo, insertándolo. Exactamente. Así que, bueno, no se va a entender nada. Lo vamos a entender al final. Supuestamente. ¿Qué pensás de esta unión, no? De lo que se denomina latino, con lo que se denomina rock. Si hay diferencias, Fito tuvo un gran encontronazo con Arjona, pero al mismo tiempo, bueno, vos tenés una gran relación musical con Shakira, Calamaro grabó con Juanes, Vicentico con Ricky Martin, digo. ¿Es bien de argentino hacer esta pregunta, inclusive? ¿Es de argentino? Bueno, claro, es un tema, ¿no? Somos argentinos y tenemos que sortear una cantidad de cosas que tenemos muy impresas en el cerebro, empezando porque somos un país de rock. Donde el rock ha sido muy, estuvo muy presente en, no sé, mi adolescencia, y yo. Entonces, mismo dentro de Argentina está el prejuicio de que sos rock o no sos rock, ¿viste? Sí, sí. Es decir, algo que ya es como medio ridículo. Por suerte caduco, me parece.'),\n",
              " Document(page_content='No sé, pero es ridículo, ¿qué sé yo? Pero también de alguna manera es herencia de aquella época en donde no decíamos música complaciente, música no complaciente, música progresiva. Comercial. Sí, Boca, River, Redondito, Soda. Iniesta García. Exacto. Entonces, como que esa cosa que tenemos así, este, la llevaremos por siempre jamás, pero bueno, no importa, digo, es un país tan musical argentina y somos muy admirados en ese aspecto por todos los otros artistas latinos que yo cono, por lo menos que he visto, ¿no? De hecho, Juanes ha venido a mi casa una vez, he sido muy fan, ¿viste? Shakira también cuando se acercó. Y si bien son otro palo, y uno podría decir, ¿no? Este, no sé yo, hacen una música que a lo mejor no es la que uno haría o la que uno consumiría, este, a veces está bueno cruzar esas experiencias. Yo he aprendido mucho con Shakira, a pesar de que ella vino a buscarme para, para que la ayudara con, con lo suyo, terminó ayudándome mucho y, y no desde el lugar de la exposición,'),\n",
              " Document(page_content='porque eso digamos, es relativo, ¿sí? Me ha conocido mucha gente, que sé yo, a través de eso, pero no es quizás lo más importante, pero sí, por ejemplo, cómo se mueve una persona que tiene ese nivel de, de exigencia. Shakira es una persona que creo que debe ser la latina más conocida en todo el mundo. Se la pasa a la India, ¿viste? Es así. Entonces, yo creo que, que en la medida que uno es menos prejuicioso, mejor le va también en la vida y mejor puede ir también como artista moviéndose, porque qué sé, porque qué sé yo. Así que yo, yo lo, una de las cosas que yo citaría como muy interesante desde la Argentina, me parece que es algo que a tener muy, muy en cuenta es que cuando hubo, cuando ocurrió lo del terremoto de Chile, que, que se organizó ese, ese festival de ayuda y de abrazo a Chile, que se organizó en tres días, que lo hizo Juan Carr con la ayuda de todas, de nuestra, que yo, pero creo, lo hizo increíblemente, la gente, bebe, la gente era, era como si fueran chilenos, eran'),\n",
              " Document(page_content='argentinos, eso no se veía antes. Totalmente. O sea, como que todos empezamos a entender que estamos en el mismo barco, ¿viste? Y el agua se está moviendo y es una agua del cual también nosotros somos responsables. Entonces, esa sensación de, de hermandad, digamos, alguna vez también, que no, que nosotros como argentinos siempre nos cuesta tragar. Absolutamente. Ver esa demostración de parte de la gente, para mí fue una de las cosas más lindas que yo he vivido en los últimos tiempos y me habló mucho también de Argentina. Gracias, ha gustado buen show, eh. No, no, a vos. No, no, no, no.')]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from pydantic import Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_core.outputs import LLMResult\n",
        "\n",
        "def get_model_config(model_name):\n",
        "    model_configs = {\n",
        "        \"gpt-3.5-turbo\": {\"max_tokens\": 4096, \"tokenizer\": \"gpt-3.5-turbo\"},\n",
        "        \"gpt-4\": {\"max_tokens\": 8192, \"tokenizer\": \"gpt-4\"},\n",
        "        \"gpt-4-32k\": {\"max_tokens\": 32768, \"tokenizer\": \"gpt-4\"},\n",
        "        \"gpt-4o-mini\": {\"max_tokens\": 128000, \"tokenizer\": \"o200k_base\"},\n",
        "    }\n",
        "    \n",
        "    if model_name in model_configs:\n",
        "        return model_configs[model_name]\n",
        "    else:\n",
        "        print(f\"Warning: Using default configuration for non-standard model name: {model_name}\")\n",
        "        return {\"max_tokens\": 4096, \"tokenizer\": \"cl100k_base\"}\n",
        "\n",
        "model_name = \"gpt-4o-mini\"\n",
        "try:\n",
        "    llm = ChatOpenAI(model=model_name)\n",
        "except ValueError as e:\n",
        "    print(f\"Error initializing ChatOpenAI with model {model_name}: {e}\")\n",
        "    print(\"Falling back to default GPT-3.5-turbo model\")\n",
        "    model_name = \"gpt-3.5-turbo\"\n",
        "    llm = ChatOpenAI(model=model_name)\n",
        "\n",
        "model_config = get_model_config(model_name)\n",
        "tokenizer = tiktoken.get_encoding(model_config[\"tokenizer\"])\n",
        "max_tokens = model_config[\"max_tokens\"]\n",
        "\n",
        "def count_tokens(text):\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "class TokenCheckLLMChain(LLMChain):\n",
        "    invocation_count: int = Field(0, description=\"Number of times the chain has been invoked\")\n",
        "    total_tokens_used: int = Field(0, description=\"Number of tokens used accumulated\")\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.invocation_count = 0\n",
        "        self.total_tokens_used = 0\n",
        "\n",
        "    def generate(self, input_list, run_manager=None):\n",
        "        results = []\n",
        "        for inputs in input_list:\n",
        "            input_text = self.prompt.format(**inputs)\n",
        "            input_tokens = count_tokens(input_text)\n",
        "            \n",
        "            self.invocation_count += 1\n",
        "            self.total_tokens_used += input_tokens\n",
        "\n",
        "            print(f\"Invocation {self.invocation_count}: Input tokens: {input_tokens}\")\n",
        "            print(f\"Maximum allowed tokens: {max_tokens}\")\n",
        "            \n",
        "            if input_tokens > max_tokens:\n",
        "                print(f\"Warning: Input tokens ({input_tokens}) exceed the model's maximum context length ({max_tokens})\")\n",
        "                print(\"Skipping this invocation\")\n",
        "                results.append(None)\n",
        "                continue\n",
        "            \n",
        "            result = super().generate([inputs], run_manager=run_manager)\n",
        "            output_tokens = count_tokens(result.generations[0][0].text)\n",
        "            self.total_tokens_used += output_tokens\n",
        "            print(f\"Invocation {self.invocation_count}: Output tokens: {output_tokens}\")\n",
        "            print(f\"Invocation {self.invocation_count}: Total tokens: {input_tokens + output_tokens}\")\n",
        "            \n",
        "            results.append(result)\n",
        "        \n",
        "        # Combine results into a single LLMResult\n",
        "        combined_generations = [r.generations[0] for r in results if r is not None]\n",
        "        combined_llm_output = {k: v for r in results if r is not None for k, v in r.llm_output.items()}\n",
        "        return LLMResult(generations=combined_generations, llm_output=combined_llm_output)\n",
        "\n",
        "map_template = \"Write a concise summary of the following: {docs}\"\n",
        "map_prompt = ChatPromptTemplate.from_template(map_template)\n",
        "map_chain = TokenCheckLLMChain(llm=llm, prompt=map_prompt)\n",
        "\n",
        "reduce_template = \"\"\"\n",
        "Write a concise summary of the following:\n",
        "\n",
        "{docs}\n",
        "\n",
        "Take these and distill it into a final, consolidated summary of the main themes.\n",
        "\"\"\"\n",
        "reduce_prompt = ChatPromptTemplate.from_template(reduce_template)\n",
        "reduce_chain = TokenCheckLLMChain(llm=llm, prompt=reduce_prompt)\n",
        "\n",
        "combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
        ")\n",
        "\n",
        "reduce_documents_chain = ReduceDocumentsChain(\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    token_max=1000,\n",
        ")\n",
        "\n",
        "map_reduce_chain = MapReduceDocumentsChain(\n",
        "    llm_chain=map_chain,\n",
        "    reduce_documents_chain=reduce_documents_chain,\n",
        "    document_variable_name=\"docs\",\n",
        "    return_intermediate_steps=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invocation 1: Input tokens: 268\n",
            "Maximum allowed tokens: 128000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invocation 1: Output tokens: 95\n",
            "Invocation 1: Total tokens: 363\n",
            "Invocation 2: Input tokens: 262\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 2: Output tokens: 153\n",
            "Invocation 2: Total tokens: 415\n",
            "Invocation 3: Input tokens: 254\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 3: Output tokens: 118\n",
            "Invocation 3: Total tokens: 372\n",
            "Invocation 4: Input tokens: 262\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 4: Output tokens: 90\n",
            "Invocation 4: Total tokens: 352\n",
            "Invocation 5: Input tokens: 251\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 5: Output tokens: 147\n",
            "Invocation 5: Total tokens: 398\n",
            "Invocation 6: Input tokens: 248\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 6: Output tokens: 106\n",
            "Invocation 6: Total tokens: 354\n",
            "Invocation 7: Input tokens: 244\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 7: Output tokens: 117\n",
            "Invocation 7: Total tokens: 361\n",
            "Invocation 8: Input tokens: 268\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 8: Output tokens: 107\n",
            "Invocation 8: Total tokens: 375\n",
            "Invocation 9: Input tokens: 254\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 9: Output tokens: 115\n",
            "Invocation 9: Total tokens: 369\n",
            "Invocation 10: Input tokens: 270\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 10: Output tokens: 123\n",
            "Invocation 10: Total tokens: 393\n",
            "Invocation 11: Input tokens: 264\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 11: Output tokens: 101\n",
            "Invocation 11: Total tokens: 365\n",
            "Invocation 12: Input tokens: 260\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 12: Output tokens: 106\n",
            "Invocation 12: Total tokens: 366\n",
            "Invocation 13: Input tokens: 153\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 13: Output tokens: 78\n",
            "Invocation 13: Total tokens: 231\n",
            "Invocation 1: Input tokens: 961\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 1: Output tokens: 225\n",
            "Invocation 1: Total tokens: 1186\n",
            "Invocation 2: Input tokens: 551\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 2: Output tokens: 249\n",
            "Invocation 2: Total tokens: 800\n",
            "Invocation 3: Input tokens: 502\n",
            "Maximum allowed tokens: 128000\n",
            "Invocation 3: Output tokens: 229\n",
            "Invocation 3: Total tokens: 731\n",
            "Final Result: Gustavo reflexiona sobre su evolución como artista desde su debut en 1987 con Soda Estéreo, destacando la calidad técnica de los eventos en Los Ángeles y su preferencia por vivir intensamente las experiencias de gira. A pesar de su éxito, enfrenta incertidumbres sobre el mercado musical y valora la conexión emocional en su trabajo. Resalta la importancia de la amistad y cohesión con sus compañeros músicos, así como la innovación y el riesgo en su proceso creativo. \n",
            "\n",
            "Leandro Fresco está trabajando en un remix exclusivo y se discute la interconexión entre la música latina y el rock en Argentina, con un énfasis en la eliminación de barreras entre géneros. Se aborda la evolución de la identidad rockera y la admiración por la música argentina, promoviendo una actitud menos prejuiciosa en el arte. Se menciona la rápida organización de un festival de ayuda tras el terremoto en Chile, evidenciando la empatía y unidad entre las personas, y se reconoce un cambio en la percepción de hermandad entre los argentinos, subrayando la responsabilidad compartida ante desafíos comunes.\n",
            "Map Chain - Total invocations: 13, Total tokens used: 4714\n",
            "Reduce Chain - Total invocations: 3, Total tokens used: 2717\n"
          ]
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "result = map_reduce_chain.run(split_docs)\n",
        "print(f\"Final Result: {result}\")\n",
        "print(f\"Map Chain - Total invocations: {map_chain.invocation_count}, Total tokens used: {map_chain.total_tokens_used}\")\n",
        "print(f\"Reduce Chain - Total invocations: {reduce_chain.invocation_count}, Total tokens used: {reduce_chain.total_tokens_used}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now, let's create a knowledge base from Ron Burgundy's video in Deep Lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#Load the texts\n",
        "with open(\"text2.txt\") as f:\n",
        "    text = f.read()\n",
        "texts = text_splitter.split_text(text)\n",
        "# Split the documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\"\", \",\",\"\\n\"])\n",
        "texts = text_splitter.split_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "NAyV9BoYHxhk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content=\"The Ron Burgundy Podcast. Yes, let's talk about it. This is a very, very exciting. You have your own podcast. You call it exciting. I got Shanghai. What are you talking about? I didn't know what a podcast was. I thought it was my own talk show on television. Turns out I'm thrown into, you know, a padded room with a sweaty microphone. Wait, when you agreed to do a podcast, you didn't know what it was? It was too much money to say no. You've done some important work too. Is this true? I'm told by my people that you cracked the Zodiac Killer case on your podcast. We did. True crimes and mysteries. They're very popular. Very popular on podcast. So we cracked the Zodiac Killer. You did. That's a murder mystery that's... Been going on. And it's been... They haven't solved. It's been unsolved for... Oh, God. I don't know how. 35, 40 years. At least. Yeah. I've been deemed to know a little more about it than you do. Look, it sounds... You should come and do my podcast for me. Yeah. But yeah,\"), Document(page_content=\"we revealed to the audience that it was Ted Cruz. And it's exciting to, you know, break information like that. Out to people. Did you have a good evidence that it was... Really good evidence. Like, you want to get specific? It's hop-notch evidence. Like evidence that anyone in police work would go like, What? This is good evidence, man. Well, okay. Where'd you get this? Yeah. Were you invited to evidence shop? Yeah. What's going on here? Yeah. This evidence is so good, it seems fishy. Yeah. But, um, no, we got him. Ted. So, anyway, Ted, if you're watching, watch out. We know you... You've named him as the killer, but he's still free and no... As far as I know, I don't know what... I don't know what he does right now, but... Okay. All right. Let's just store for season two of the podcast. I mean, you set us pretty high bar for season one with your solving cases like that. What do you got? Solving cases. Season one, we were stuck in an elevator for one podcast. We did one for my haunted\"), Document(page_content=\"garage. What else? We interviewed RuPaul. Yeah. So we pretty much climbed the mountain. Yeah. Season two will be a bit of a letdown. Yeah. That's how he's... We're not really drawing that hard. Yeah. And some of them are just 45 minutes of dead air. Yeah. I'm going to give you a little advice. When you're promoting something, you want to make it sound, you want to build it up. Well, but I've never lied to my viewers. So, I'd like to build it up. Look. You can't make chicken salad out of chicken shit. I've always said it. Well, you heard it from the man himself. So, you make a good case. You got to listen to... Season two. Not that good. Season two. Season two of the Ron Burgundy podcast has been able to date wherever. Wherever you listen to my wife. Yeah, wherever. If you find out, tell me. Ron Burgundy.\")]\n"
          ]
        }
      ],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs = [Document(page_content=t) for t in texts]\n",
        "print(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb-zejHLHzk5",
        "outputId": "08f9b93a-0bac-4b95-e318-0600c034ca9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep Lake Dataset in hub://macayaven/ron_burgundy already exists, loading from the storage\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating 3 embeddings in 1 batches of size 3:: 100%|██████████| 1/1 [00:05<00:00,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset(path='hub://macayaven/ron_burgundy', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype      shape     dtype  compression\n",
            "  -------    -------    -------   -------  ------- \n",
            " embedding  embedding  (3, 1536)  float32   None   \n",
            "    id        text      (3, 1)      str     None   \n",
            " metadata     json      (3, 1)      str     None   \n",
            "   text       text      (3, 1)      str     None   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['23545fda-5f58-11ef-9ff6-0eb96800271b',\n",
              " '235460f2-5f58-11ef-9ff6-0eb96800271b',\n",
              " '23546124-5f58-11ef-9ff6-0eb96800271b']"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "\n",
        "# create Deep Lake dataset\n",
        "my_activeloop_org_id = \"macayaven\"\n",
        "my_activeloop_dataset_name = \"ron_burgundy\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
        "db.add_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "hL9hylaCIKvl"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()\n",
        "retriever.search_kwargs['distance_metric'] = 'cos'\n",
        "retriever.search_kwargs['k'] = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "_yK-LTVfJ2Ue"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = \"\"\"Use the following pieces of transcripts from a video to answer the question in bullet points and summarized. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Summarized answer in bullter points:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "z6Qu84SMJ_H4"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=retriever,\n",
        "                                 chain_type_kwargs=chain_type_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNMFjbjjKcj_",
        "outputId": "1b431058-0ac2-43b2-be46-751f1cb4ed29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- The transcripts do not explicitly label Ron Burgundy as a genius.\n",
            "- He claims to have solved the Zodiac Killer case on his podcast, which he presents as a significant accomplishment.\n",
            "- He acknowledges he didn't know what a podcast was when he agreed to do it, indicating he may not have been aware of the medium's complexities.\n",
            "- The conversation includes humorous and sarcastic elements, suggesting that some claims may not be taken seriously.\n",
            "- Overall, the portrayal of Ron Burgundy seems to be more comedic than serious, leaving his genius status ambiguous.\n",
            "- **Best Traits:**\n",
            "  - Honest: Ron emphasizes that he has never lied to his viewers, showing integrity in his promotion.\n",
            "  - Humorous: His comments about \"making chicken salad out of chicken shit\" reflect a comedic perspective.\n",
            "  - Engaging: He mentions exciting moments like interviewing RuPaul and breaking news, indicating he can capture audience interest.\n",
            "\n",
            "- **Worst Traits:**\n",
            "  - Self-deprecating: Ron seems to belittle his own work by suggesting that season two of his podcast might be a letdown.\n",
            "  - Overly critical: He mentions that some content is just \"45 minutes of dead air,\" suggesting a lack of confidence in certain episodes.\n",
            "  - Lack of awareness: Initially, he didn't even know what a podcast was, which may indicate a disconnect with the medium he is involved in.\n",
            "- The transcript does not provide information about how many wives Ron Burgundy has.\n",
            "- There is no mention of Ron's marital status or the number of wives he may have. \n",
            "- Therefore, I don't know the answer to the question.\n"
          ]
        }
      ],
      "source": [
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs=chain_type_kwargs)\n",
        "print(qa.run(\"Is Ron Burgundy a genious?\"))\n",
        "print(qa.run(\"What are the best and worst traits that you can see in Ron?\"))\n",
        "print(qa.run(\"How many wifes did Ron have?\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNB1HgDlWxbtutn+LeF4l+J",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
